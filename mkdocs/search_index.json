{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to RediSearch\n\n\nRediSearch is a Full-Text search over Redis, developed by RedisLabs. \n\n\nThe source code is available at \nhttps://github.com/RedisLabsModules/RediSearch\n.\n\n\nLatest Release: \n0.12 (Preview)\n\n\nOverview\n\n\nRedisearch impements a search engine on top of redis, but unlike other redis \nsearch libraries, it does not use internal data structures like sorted sets.\n\n\nInverted indexes are stored on top of Redis strings using binary encoding,\nand not mapped to existing data structures (see \nDESIGN.md\n). \n\n\nThis allows much faster performance, significantly less memory consumption, and\nmore advanced features like exact phrase matching, that are not possible with \ntraditional redis search approaches. \n\n\nClient Libraries\n\n\n\n\n\n\nPython\n: \nhttps://github.com/RedisLabs/redisearch-py\n\n\n\n\n\n\nJava\n: \nhttps://github.com/RedisLabs/JRediSearch\n\n\n\n\n\n\nPrimary Features:\n\n\n\n\nFull-Text indexing of multiple fields in documents.\n\n\nIncremental indexing without performance loss.\n\n\nDocument ranking (provided manually by the user at index time).\n\n\nField weights.\n\n\nAuto-complete suggestions (with fuzzy prefix suggestions)\n\n\nExact Phrase Search of up to 8 words.\n\n\nStemming based query expansion in \nmany languages\n (using \nSnowball\n).\n\n\nSupport for custom functions for query expansion and scoring (see \nExtensions\n).\n\n\nLimiting searches to specific document fields (up to 8 fields supported).\n\n\nNumeric filters and ranges.\n\n\nGeo filtering using Redis' own Geo-commands. \n\n\nSupports any utf-8 encoded text.\n\n\nRetrieve full document content or just ids\n\n\nAutomatically index existing HASH keys as documents.\n\n\nDocument deletion and updating with index garbage collection.", 
            "title": "RediSearch"
        }, 
        {
            "location": "/#welcome-to-redisearch", 
            "text": "RediSearch is a Full-Text search over Redis, developed by RedisLabs.   The source code is available at  https://github.com/RedisLabsModules/RediSearch .", 
            "title": "Welcome to RediSearch"
        }, 
        {
            "location": "/#latest-release-012-preview", 
            "text": "", 
            "title": "Latest Release: 0.12 (Preview)"
        }, 
        {
            "location": "/#overview", 
            "text": "Redisearch impements a search engine on top of redis, but unlike other redis \nsearch libraries, it does not use internal data structures like sorted sets.  Inverted indexes are stored on top of Redis strings using binary encoding,\nand not mapped to existing data structures (see  DESIGN.md ).   This allows much faster performance, significantly less memory consumption, and\nmore advanced features like exact phrase matching, that are not possible with \ntraditional redis search approaches.", 
            "title": "Overview"
        }, 
        {
            "location": "/#client-libraries", 
            "text": "Python :  https://github.com/RedisLabs/redisearch-py    Java :  https://github.com/RedisLabs/JRediSearch", 
            "title": "Client Libraries"
        }, 
        {
            "location": "/#primary-features", 
            "text": "Full-Text indexing of multiple fields in documents.  Incremental indexing without performance loss.  Document ranking (provided manually by the user at index time).  Field weights.  Auto-complete suggestions (with fuzzy prefix suggestions)  Exact Phrase Search of up to 8 words.  Stemming based query expansion in  many languages  (using  Snowball ).  Support for custom functions for query expansion and scoring (see  Extensions ).  Limiting searches to specific document fields (up to 8 fields supported).  Numeric filters and ranges.  Geo filtering using Redis' own Geo-commands.   Supports any utf-8 encoded text.  Retrieve full document content or just ids  Automatically index existing HASH keys as documents.  Document deletion and updating with index garbage collection.", 
            "title": "Primary Features:"
        }, 
        {
            "location": "/Quick_Start/", 
            "text": "Quick Start Guide for RediSearch:\n\n\nBuilding and running:\n\n\ngit clone https://github.com/RedisLabsModules/RediSearch.git\n\ncd\n RediSearch/src\nmake all\n\n\n# Assuming you have a redis build from the unstable branch:\n\n/path/to/redis-server --loadmodule ./module.so\n\n\n\n\n\nCreating an index with fields and weights (default weight is 1.0):\n\n\n127.0.0.1:6379\n FT.CREATE myIdx SCHEMA title TEXT WEIGHT 5.0 body TEXT url TEXT\nOK \n\n\n\n\n\nAdding documents to the index:\n\n\n127.0.0.1:6379\n FT.ADD myIdx doc1 1.0 FIELDS title \nhello world\n body \nlorem ipsum\n url \nhttp://redis.io\n \nOK\n\n\n\n\n\nSearching the index:\n\n\n127.0.0.1:6379\n FT.SEARCH myIdx \nhello world\n LIMIT 0 10\n1) (integer) 1\n2) \ndoc1\n\n3) 1) \ntitle\n\n   2) \nhello world\n\n   3) \nbody\n\n   4) \nlorem ipsum\n\n   5) \nurl\n\n   6) \nhttp://redis.io\n\n\n\n\n\n\n\n\nNOTE\n: Input is expected to be valid utf-8 or ascii. The engine cannot handle wide character unicode at the moment. \n\n\n\n\nDropping the index:\n\n\n127.0.0.1:6379\n FT.DROP myIdx\nOK\n\n\n\n\n\nAdding and getting Auto-complete suggestions:\n\n\n127.0.0.1:6379\n FT.SUGADD autocomplete \nhello world\n 100\nOK\n\n127.0.0.1:6379\n FT.SUGGET autocomplete \nhe\n\n1) \nhello world", 
            "title": "Quick Start"
        }, 
        {
            "location": "/Quick_Start/#quick-start-guide-for-redisearch", 
            "text": "", 
            "title": "Quick Start Guide for RediSearch:"
        }, 
        {
            "location": "/Quick_Start/#building-and-running", 
            "text": "git clone https://github.com/RedisLabsModules/RediSearch.git cd  RediSearch/src\nmake all # Assuming you have a redis build from the unstable branch: \n/path/to/redis-server --loadmodule ./module.so", 
            "title": "Building and running:"
        }, 
        {
            "location": "/Quick_Start/#creating-an-index-with-fields-and-weights-default-weight-is-10", 
            "text": "127.0.0.1:6379  FT.CREATE myIdx SCHEMA title TEXT WEIGHT 5.0 body TEXT url TEXT\nOK", 
            "title": "Creating an index with fields and weights (default weight is 1.0):"
        }, 
        {
            "location": "/Quick_Start/#adding-documents-to-the-index", 
            "text": "127.0.0.1:6379  FT.ADD myIdx doc1 1.0 FIELDS title  hello world  body  lorem ipsum  url  http://redis.io  \nOK", 
            "title": "Adding documents to the index:"
        }, 
        {
            "location": "/Quick_Start/#searching-the-index", 
            "text": "127.0.0.1:6379  FT.SEARCH myIdx  hello world  LIMIT 0 10\n1) (integer) 1\n2)  doc1 \n3) 1)  title \n   2)  hello world \n   3)  body \n   4)  lorem ipsum \n   5)  url \n   6)  http://redis.io    NOTE : Input is expected to be valid utf-8 or ascii. The engine cannot handle wide character unicode at the moment.", 
            "title": "Searching the index:"
        }, 
        {
            "location": "/Quick_Start/#dropping-the-index", 
            "text": "127.0.0.1:6379  FT.DROP myIdx\nOK", 
            "title": "Dropping the index:"
        }, 
        {
            "location": "/Quick_Start/#adding-and-getting-auto-complete-suggestions", 
            "text": "127.0.0.1:6379  FT.SUGADD autocomplete  hello world  100\nOK\n\n127.0.0.1:6379  FT.SUGGET autocomplete  he \n1)  hello world", 
            "title": "Adding and getting Auto-complete suggestions:"
        }, 
        {
            "location": "/Commands/", 
            "text": "RediSeach Full Command Documentation\n\n\nFT.CREATE\n\n\nFormat:\n\n\n  FT.CREATE {index} \n    [NOOFFSETS] [NOFIELDS] [NOSCOREIDX]\n    SCHEMA {field} [TEXT [WEIGHT {weight}] | NUMERIC | GEO] ...\n\n\n\n\n\nDescription:\n\n\nCreates an index with the given spec. The index name will be used in all the key names\nso keep it short!\n\n\nParameters:\n\n\n\n\n\n\nindex\n: the index name to create. If it exists the old spec will be overwritten\n\n\n\n\n\n\nNOOFFSETS\n: If set, we do not store term offsets for documents (saves memory, does not allow exact searches)\n\n\n\n\n\n\nNOFIELDS\n: If set, we do not store field bits for each term. Saves memory, does not allow filtering by specific fields.\n\n\n\n\n\n\nNOSCOREIDX\n: If set, we avoid saving the top results for single words. Saves a lot of memory, slows down searches for common single word queries.\n\n\n\n\n\n\nSCHEMA {field} {options...}\n: After the SCHEMA keyword we define the index fields. \nThey can be numeric, textual or geographical. For textual fields we optionally specify a weight. The default weight is 1.0.\n\n\n\n\n\n\nComplexity\n\n\nO(1)\n\n\nReturns:\n\n\nOK or an error\n\n\n\n\nFT.ADD\n\n\nFormat:\n\n\nFT.ADD {index} {docId} {score} \n  [NOSAVE]\n  [REPLACE]\n  [LANGUAGE {language}] \n  [PAYLOAD {payload}]\n  FIELDS {field} {value} [{field} {value}...]\n\n\n\n\n\nDescription\n\n\nAdd a documet to the index.\n\n\nParameters:\n\n\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\n\n\n\n\ndocId\n: The document's id that will be returned from searches. \n  Note that the same docId cannot be added twice to the same index\n\n\n\n\n\n\nscore\n: The document's rank based on the user's ranking. This must be between 0.0 and 1.0. \n  If you don't have a score just set it to 1\n\n\n\n\n\n\nNOSAVE\n: If set to true, we will not save the actual document in the index and only index it.\n\n\n\n\n\n\nREPLACE\n: If set, we will do an UPSERT style insertion - and delete an older version of the document if it exists.\n\n\n\n\n\n\nFIELDS\n: Following the FIELDS specifier, we are looking for pairs of  \n{field} {value}\n to be indexed.\n\n\n\n\n\n\nEach field will be scored based on the index spec given in FT.CREATE. \n  Passing fields that are not in the index spec will make them be stored as part of the document, or ignored if NOSAVE is set \n\n\n\n\n\n\nPAYLOAD {payload}\n: Optionally set a binary safe payload string to the document, \n  that can be evaluated at query time by a custom scoring function, or retrieved to the client.\n\n\n\n\n\n\nLANGUAGE language\n: If set, we use a stemmer for the supplied langauge during indexing. Defaults to English. \n  If an unsupported language is sent, the command returns an error. \n  The supported languages are:\n\n\n\n\n\n\n\n\n\"arabic\",  \"danish\",    \"dutch\",   \"english\",   \"finnish\",    \"french\",\n\"german\",  \"hungarian\", \"italian\", \"norwegian\", \"portuguese\", \"romanian\",\n\"russian\", \"spanish\",   \"swedish\", \"tamil\",     \"turkish\"\n\n\n\n\nComplexity\n\n\nO(n), where n is the number of tokens in the document\n\n\nReturns\n\n\nOK on success, or an error if something went wrong.\n\n\n\n\nFT.ADDHASH\n\n\nFormat\n\n\n \nFT\n.\nADDHASH\n \n{\nindex\n}\n \n{\ndocId\n}\n \n{\nscore\n}\n \n[\nLANGUAGE\n \nlanguage\n]\n \n[\nREPLACE\n]\n\n\n\n\n\n\nDescription\n\n\nAdd a documet to the index from an existing HASH key in Redis.\n\n\nParameters:\n\n\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\n\n\n\n\ndocId\n: The document's id. This has to be an existing HASH key in redis that will hold the fields \n    the index needs.\n\n\n\n\n\n\nscore\n: The document's rank based on the user's ranking. This must be between 0.0 and 1.0. \n  If you don't have a score just set it to 1\n\n\n\n\n\n\nREPLACE\n: If set, we will do an UPSERT style insertion - and delete an older version of the document if it exists.\n\n\n\n\n\n\nLANGUAGE language\n: If set, we use a stemmer for the supplied langauge during indexing. Defaults to English. \n  If an unsupported language is sent, the command returns an error. \n  The supported languages are:\n\n\n\n\n\n\n\n\n\"arabic\",  \"danish\",    \"dutch\",   \"english\",   \"finnish\",    \"french\",\n\"german\",  \"hungarian\", \"italian\", \"norwegian\", \"portuguese\", \"romanian\",\n\"russian\", \"spanish\",   \"swedish\", \"tamil\",     \"turkish\"\n\n\n\n\nComplexity\n\n\nO(n), where n is the number of tokens in the document\n\n\nReturns\n\n\nOK on success, or an error if something went wrong.\n\n\n\n\nFT.INFO\n\n\nFormat\n\n\nFT.INFO {index} \n\n\n\n\n\nDescription\n\n\nReturn information and statistics on the index. Returned values include:\n\n\n\n\nNumber of documents.\n\n\nNumber of distinct terms.\n\n\nAverage bytes per record.\n\n\nSize and capacity of the index buffers.\n\n\n\n\nExample:\n\n\n127.0.0.1:6379\n ft.info wik{0}\n 1) index_name\n 2) wikipedia\n 3) fields\n 4) 1) 1) title\n       2) type\n       3) FULLTEXT\n       4) weight\n       5) \n1\n\n    2) 1) body\n       2) type\n       3) FULLTEXT\n       4) weight\n       5) \n1\n\n 5) num_docs\n 6) \n502694\n\n 7) num_terms\n 8) \n439158\n\n 9) num_records\n10) \n8098583\n\n11) inverted_sz_mb\n12) \n45.58\n13) inverted_cap_mb\n14) \n56.61\n15) inverted_cap_ovh\n16) \n0.19\n17) offset_vectors_sz_mb\n18) \n9.27\n19) skip_index_size_mb\n20) \n7.35\n21) score_index_size_mb\n22) \n30.8\n23) records_per_doc_avg\n24) \n16.1\n25) bytes_per_record_avg\n26) \n5.90\n27) offsets_per_term_avg\n28) \n1.20\n29) offset_bits_per_record_avg\n30) \n8.00\n\n\n\n\n\nParameters\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\n\n\nComplexity\n\n\nO(1)\n\n\nReturns\n\n\nArray Response. A nested array of keys and values.\n\n\n\n\nFT.SEARCH\n\n\nFormat\n\n\nFT.SEARCH {index} {query} [NOCONTENT] [VERBATIM] [NOSTOPWORDS] [WITHSCORES] [WITHPAYLOADS]\n  [FILTER {numeric_field} {min} {max}] ...\n  [GEOFILTER {geo_field} {lon} {lat} {raius} m|km|mi|ft]\n  [INKEYS {num} {key} ... ]\n  [INFIELDS {num {field} ... ]\n  [SLOP {slop}] [INORDER]\n    [LANGUAGE {language}]\n    [EXPANDER {expander}]\n  [SCORER {scorer}]\n  [LIMIT offset num]\n\n\n\n\n\nDescription\n\n\nSearch the index with a textual query, returning either documents or just ids.\n\n\nParameters\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\nquery\n: the text query to search. If it's more than a single word, put it in quotes.\n  See below for documentation on query syntax. \n\n\nNOCONTENT\n: If it appears after the query, we only return the document ids and not \n  the content. This is useful if rediseach is only an index on an external document collection\n\n\nLIMIT first num\n: If the parameters appear after the query, we limit the results to \n  the offset and number of results given. The default is 0 10\n\n\nINFIELDS {num} {field} ...\n: If set, filter the results to ones appearing only in specific\n  fields of the document, like title or url. num is the number of specified field arguments\n\n\nINKEYS {num} {field} ...\n: If set, we limit the result to a given set of keys specified in the list. \n  the first argument must be the length of the list, and greater than zero.\n  Non existent keys are ignored - unless all the keys are non existent.\n\n\nSLOP {slop}\n: If set, we allow a maximum of N intervening number of unmatched offsets between phrase terms. (i.e the slop for exact phrases is 0)\n\n\nINORDER\n: If set, and usually used in conjunction with SLOP, we make sure the query terms appear in the same order in the document as in the query, regardless of the offsets between them. \n\n\nFILTER numeric_field min max\n: If set, and numeric_field is defined as a numeric field in \n  FT.CREATE, we will limit results to those having numeric values ranging between min and max.\n  min and max follow ZRANGE syntax, and can be \n-inf\n, \n+inf\n and use \n(\n for exclusive ranges. \n  Multiple numeric filters for different fields are supported in one query.\n\n\nGEOFILTER {geo_field} {lon} {lat} {raius} m|km|mi|ft\n: If set, we filter the results to a given radius \n  from lon and lat. Radius is given as a number and units. See \nGEORADIUS\n for more details. \n\n\nNOSTOPWORDS\n: If set, we do not filter stopwords from the query. \n\n\nWITHSCORES\n: If set, we also return the relative internal score of each document. this can be\n  used to merge results from multiple instances\n\n\nVERBATIM\n: if set, we do not try to use stemming for query expansion but search the query terms verbatim.\n\n\nLANGUAGE {language}\n: If set, we use a stemmer for the supplied langauge during search for query expansion. \n  Defaults to English. If an unsupported language is sent, the command returns an error. See FT.ADD for the list of languages.\n\n\nEXPANDER {expander}\n: If set, we will use a custom query expander instead of the stemmer. \nSee Extensions\n.\n\n\nSCORER {scorer}\n: If set, we will use a custom scoring function defined by the user. \nSee Extensions\n.\n\n\nPAYLOAD {payload}\n: Add an arbitrary, binary safe payload that will be exposed to custom scoring functions. \nSee Extensions\n.\n\n\nWITHPAYLOADS\n: If set, we retrieve optional document payloads (see FT.ADD). \n  the payloads follow the document id, and if \nWITHSCORES\n was set, follow the scores.\n\n\n\n\nComplexity\n\n\nO(n) for single word queries (though for popular words we save a cache of the top 50 results).\n\n\nComplexity for complex queries changes, but in general it's proportional to the number of words and the number of intersection points between them.\n\n\nReturns\n\n\nArray reply,\n where the first element is the total number of results, and then pairs of document id, and a nested array of field/value. \n\n\nIf \nNOCONTENT\n was given, we return an array where the first element is the total number of results, and the rest of the members are document ids.\n\n\n\n\nFT.DEL\n\n\nFormat\n\n\nFT.DEL {index} {doc_id}\n\n\n\n\n\nDescription\n\n\nDelete a document from the index. Returns 1 if the document was in the index, or 0 if not. \n\n\nAfter deletion, the document can be re-added to the index. It will get a different internal id and will be a new document from the index's POV.\n\n\nNOTE\n: This does not actually delete the document from the index, just marks it as deleted. \nThus, deleting and re-inserting the same document over and over will inflate the index size with each re-insertion.\n\n\nParameters\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\ndoc_id\n: the id of the document to be deleted. It does not actually delete the HASH key in which the document is stored. Use DEL to do that manually if needed.\n\n\n\n\nComplexity\n\n\nO(1)\n\n\nReturns\n\n\nInteger Reply: 1 if the document was deleted, 0 if not.\n\n\n\n\nFT.DROP\n\n\nFormat\n\n\nFT.DROP {index}\n\n\n\n\n\nDescription\n\n\nDeletes all the keys associated with the index. \n\n\nIf no other data is on the redis instance, this is equivalent to FLUSHDB, apart from the fact\nthat the index specification is not deleted.\n\n\nParameters\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\n\n\nReturns\n\n\nStatus Reply: OK on success.\n\n\n\n\nFT.OPTIMIZE\n\n\nFormat\n\n\nFT.OPTIMIZE {index}\n\n\n\n\n\nDescription\n\n\nAfter the index is built (and doesn't need to be updated again withuot a complete rebuild)\nwe can optimize memory consumption by trimming all index buffers to their actual size.\n\n\nWarning 1\n: Do not run it if you intend to update your index afterward.\n\n\nWarning 2\n: This blocks redis for a long time. Do not run it on production instances\n\n\nParameters\n\n\n\n\nindex\n: The Fulltext index name. The index must be first created with FT.CREATE\n\n\n\n\nReturns:\n\n\nInteger Reply - the number of index entries optimized.\n\n\n\n\nFT.SUGGADD\n\n\nFormat\n\n\nFT.SUGADD {key} {string} {score} [INCR]\n\n\n\n\n\nDescription\n\n\nAdd a suggestion string to an auto-complete suggestion dictionary. This is disconnected from the\nindex definitions, and leaves creating and updating suggestino dictionaries to the user.\n\n\nParameters\n\n\n\n\nkey\n: the suggestion dictionary key.\n\n\nstring\n: the suggestion string we index\n\n\nscore\n: a floating point number of the suggestion string's weight\n\n\nINCR\n: if set, we increment the existing entry of the suggestion by the given score, instead of replacing the score. This is useful for updating the dictionary based on user queries in real time\n\n\n\n\nReturns:\n\n\nInteger Reply: the current size of the suggestion dictionary.\n\n\n\n\nFT.SUGGET\n\n\nFormat\n\n\nFT\n.\nSUGGET\n \n{\nkey\n}\n \n{\nprefix\n}\n \n[\nFUZZY\n]\n \n[\nMAX\n \nnum\n]\n\n\n\n\n\n\nDescription\n\n\nGet completion suggestions for a prefix\n\n\nParameters:\n\n\n\n\nkey\n: the suggestion dictionary key.\n\n\nprefix\n: the prefix to complete on\n\n\nFUZZY\n: if set,we do a fuzzy prefix search, including prefixes at levenshtein distance of 1 from the prefix sent\n\n\nMAX num\n: If set, we limit the results to a maximum of \nnum\n. (\nNote\n: The default is 5, and the number cannot be greater than 10).\n\n\nWITHSCORES\n: If set, we also return the score of each suggestion. this can be\n  used to merge results from multiple instances\n\n\n\n\nReturns:\n\n\nArray Reply: a list of the top suggestions matching the prefix, optionally with score after each entry\n\n\n\n\nFT.SUGDEL\n\n\nFormat\n\n\nFT.SUGDEL {key} {string}\n\n\n\n\n\nDescription\n\n\nDelete a string from a suggestion index. \n\n\nParameters\n\n\n\n\nkey\n: the suggestion dictionary key.\n\n\nstring\n: the string to delete\n\n\n\n\nReturns:\n\n\nInteger Reply: 1 if the string was found and deleted, 0 otherwise.\n\n\n\n\nFT.SUGLEN\n\n\nFormat\n\n\nFT.SUGLEN {key}\n\n\n\n\n\nDescription\n\n\nGet the size of an autoc-complete suggestion dictionary\n\n\nParameters\n\n\n\n\nkey\n: the suggestion dictionary key.\n\n\n\n\nReturns:\n\n\nInteger Reply: the current size of the suggestion dictionary.", 
            "title": "Commands"
        }, 
        {
            "location": "/Commands/#rediseach-full-command-documentation", 
            "text": "", 
            "title": "RediSeach Full Command Documentation"
        }, 
        {
            "location": "/Commands/#ftcreate", 
            "text": "", 
            "title": "FT.CREATE"
        }, 
        {
            "location": "/Commands/#format", 
            "text": "FT.CREATE {index} \n    [NOOFFSETS] [NOFIELDS] [NOSCOREIDX]\n    SCHEMA {field} [TEXT [WEIGHT {weight}] | NUMERIC | GEO] ...", 
            "title": "Format:"
        }, 
        {
            "location": "/Commands/#description", 
            "text": "Creates an index with the given spec. The index name will be used in all the key names\nso keep it short!", 
            "title": "Description:"
        }, 
        {
            "location": "/Commands/#parameters", 
            "text": "index : the index name to create. If it exists the old spec will be overwritten    NOOFFSETS : If set, we do not store term offsets for documents (saves memory, does not allow exact searches)    NOFIELDS : If set, we do not store field bits for each term. Saves memory, does not allow filtering by specific fields.    NOSCOREIDX : If set, we avoid saving the top results for single words. Saves a lot of memory, slows down searches for common single word queries.    SCHEMA {field} {options...} : After the SCHEMA keyword we define the index fields. \nThey can be numeric, textual or geographical. For textual fields we optionally specify a weight. The default weight is 1.0.", 
            "title": "Parameters:"
        }, 
        {
            "location": "/Commands/#complexity", 
            "text": "O(1)", 
            "title": "Complexity"
        }, 
        {
            "location": "/Commands/#returns", 
            "text": "OK or an error", 
            "title": "Returns:"
        }, 
        {
            "location": "/Commands/#ftadd", 
            "text": "", 
            "title": "FT.ADD"
        }, 
        {
            "location": "/Commands/#format_1", 
            "text": "FT.ADD {index} {docId} {score} \n  [NOSAVE]\n  [REPLACE]\n  [LANGUAGE {language}] \n  [PAYLOAD {payload}]\n  FIELDS {field} {value} [{field} {value}...]", 
            "title": "Format:"
        }, 
        {
            "location": "/Commands/#description_1", 
            "text": "Add a documet to the index.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_1", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE    docId : The document's id that will be returned from searches. \n  Note that the same docId cannot be added twice to the same index    score : The document's rank based on the user's ranking. This must be between 0.0 and 1.0. \n  If you don't have a score just set it to 1    NOSAVE : If set to true, we will not save the actual document in the index and only index it.    REPLACE : If set, we will do an UPSERT style insertion - and delete an older version of the document if it exists.    FIELDS : Following the FIELDS specifier, we are looking for pairs of   {field} {value}  to be indexed.    Each field will be scored based on the index spec given in FT.CREATE. \n  Passing fields that are not in the index spec will make them be stored as part of the document, or ignored if NOSAVE is set     PAYLOAD {payload} : Optionally set a binary safe payload string to the document, \n  that can be evaluated at query time by a custom scoring function, or retrieved to the client.    LANGUAGE language : If set, we use a stemmer for the supplied langauge during indexing. Defaults to English. \n  If an unsupported language is sent, the command returns an error. \n  The supported languages are:     \"arabic\",  \"danish\",    \"dutch\",   \"english\",   \"finnish\",    \"french\",\n\"german\",  \"hungarian\", \"italian\", \"norwegian\", \"portuguese\", \"romanian\",\n\"russian\", \"spanish\",   \"swedish\", \"tamil\",     \"turkish\"", 
            "title": "Parameters:"
        }, 
        {
            "location": "/Commands/#complexity_1", 
            "text": "O(n), where n is the number of tokens in the document", 
            "title": "Complexity"
        }, 
        {
            "location": "/Commands/#returns_1", 
            "text": "OK on success, or an error if something went wrong.", 
            "title": "Returns"
        }, 
        {
            "location": "/Commands/#ftaddhash", 
            "text": "", 
            "title": "FT.ADDHASH"
        }, 
        {
            "location": "/Commands/#format_2", 
            "text": "FT . ADDHASH   { index }   { docId }   { score }   [ LANGUAGE   language ]   [ REPLACE ]", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_2", 
            "text": "Add a documet to the index from an existing HASH key in Redis.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_2", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE    docId : The document's id. This has to be an existing HASH key in redis that will hold the fields \n    the index needs.    score : The document's rank based on the user's ranking. This must be between 0.0 and 1.0. \n  If you don't have a score just set it to 1    REPLACE : If set, we will do an UPSERT style insertion - and delete an older version of the document if it exists.    LANGUAGE language : If set, we use a stemmer for the supplied langauge during indexing. Defaults to English. \n  If an unsupported language is sent, the command returns an error. \n  The supported languages are:     \"arabic\",  \"danish\",    \"dutch\",   \"english\",   \"finnish\",    \"french\",\n\"german\",  \"hungarian\", \"italian\", \"norwegian\", \"portuguese\", \"romanian\",\n\"russian\", \"spanish\",   \"swedish\", \"tamil\",     \"turkish\"", 
            "title": "Parameters:"
        }, 
        {
            "location": "/Commands/#complexity_2", 
            "text": "O(n), where n is the number of tokens in the document", 
            "title": "Complexity"
        }, 
        {
            "location": "/Commands/#returns_2", 
            "text": "OK on success, or an error if something went wrong.", 
            "title": "Returns"
        }, 
        {
            "location": "/Commands/#ftinfo", 
            "text": "", 
            "title": "FT.INFO"
        }, 
        {
            "location": "/Commands/#format_3", 
            "text": "FT.INFO {index}", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_3", 
            "text": "Return information and statistics on the index. Returned values include:   Number of documents.  Number of distinct terms.  Average bytes per record.  Size and capacity of the index buffers.   Example:  127.0.0.1:6379  ft.info wik{0}\n 1) index_name\n 2) wikipedia\n 3) fields\n 4) 1) 1) title\n       2) type\n       3) FULLTEXT\n       4) weight\n       5)  1 \n    2) 1) body\n       2) type\n       3) FULLTEXT\n       4) weight\n       5)  1 \n 5) num_docs\n 6)  502694 \n 7) num_terms\n 8)  439158 \n 9) num_records\n10)  8098583 \n11) inverted_sz_mb\n12)  45.58\n13) inverted_cap_mb\n14)  56.61\n15) inverted_cap_ovh\n16)  0.19\n17) offset_vectors_sz_mb\n18)  9.27\n19) skip_index_size_mb\n20)  7.35\n21) score_index_size_mb\n22)  30.8\n23) records_per_doc_avg\n24)  16.1\n25) bytes_per_record_avg\n26)  5.90\n27) offsets_per_term_avg\n28)  1.20\n29) offset_bits_per_record_avg\n30)  8.00", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_3", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#complexity_3", 
            "text": "O(1)", 
            "title": "Complexity"
        }, 
        {
            "location": "/Commands/#returns_3", 
            "text": "Array Response. A nested array of keys and values.", 
            "title": "Returns"
        }, 
        {
            "location": "/Commands/#ftsearch", 
            "text": "", 
            "title": "FT.SEARCH"
        }, 
        {
            "location": "/Commands/#format_4", 
            "text": "FT.SEARCH {index} {query} [NOCONTENT] [VERBATIM] [NOSTOPWORDS] [WITHSCORES] [WITHPAYLOADS]\n  [FILTER {numeric_field} {min} {max}] ...\n  [GEOFILTER {geo_field} {lon} {lat} {raius} m|km|mi|ft]\n  [INKEYS {num} {key} ... ]\n  [INFIELDS {num {field} ... ]\n  [SLOP {slop}] [INORDER]\n    [LANGUAGE {language}]\n    [EXPANDER {expander}]\n  [SCORER {scorer}]\n  [LIMIT offset num]", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_4", 
            "text": "Search the index with a textual query, returning either documents or just ids.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_4", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE  query : the text query to search. If it's more than a single word, put it in quotes.\n  See below for documentation on query syntax.   NOCONTENT : If it appears after the query, we only return the document ids and not \n  the content. This is useful if rediseach is only an index on an external document collection  LIMIT first num : If the parameters appear after the query, we limit the results to \n  the offset and number of results given. The default is 0 10  INFIELDS {num} {field} ... : If set, filter the results to ones appearing only in specific\n  fields of the document, like title or url. num is the number of specified field arguments  INKEYS {num} {field} ... : If set, we limit the result to a given set of keys specified in the list. \n  the first argument must be the length of the list, and greater than zero.\n  Non existent keys are ignored - unless all the keys are non existent.  SLOP {slop} : If set, we allow a maximum of N intervening number of unmatched offsets between phrase terms. (i.e the slop for exact phrases is 0)  INORDER : If set, and usually used in conjunction with SLOP, we make sure the query terms appear in the same order in the document as in the query, regardless of the offsets between them.   FILTER numeric_field min max : If set, and numeric_field is defined as a numeric field in \n  FT.CREATE, we will limit results to those having numeric values ranging between min and max.\n  min and max follow ZRANGE syntax, and can be  -inf ,  +inf  and use  (  for exclusive ranges. \n  Multiple numeric filters for different fields are supported in one query.  GEOFILTER {geo_field} {lon} {lat} {raius} m|km|mi|ft : If set, we filter the results to a given radius \n  from lon and lat. Radius is given as a number and units. See  GEORADIUS  for more details.   NOSTOPWORDS : If set, we do not filter stopwords from the query.   WITHSCORES : If set, we also return the relative internal score of each document. this can be\n  used to merge results from multiple instances  VERBATIM : if set, we do not try to use stemming for query expansion but search the query terms verbatim.  LANGUAGE {language} : If set, we use a stemmer for the supplied langauge during search for query expansion. \n  Defaults to English. If an unsupported language is sent, the command returns an error. See FT.ADD for the list of languages.  EXPANDER {expander} : If set, we will use a custom query expander instead of the stemmer.  See Extensions .  SCORER {scorer} : If set, we will use a custom scoring function defined by the user.  See Extensions .  PAYLOAD {payload} : Add an arbitrary, binary safe payload that will be exposed to custom scoring functions.  See Extensions .  WITHPAYLOADS : If set, we retrieve optional document payloads (see FT.ADD). \n  the payloads follow the document id, and if  WITHSCORES  was set, follow the scores.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#complexity_4", 
            "text": "O(n) for single word queries (though for popular words we save a cache of the top 50 results).  Complexity for complex queries changes, but in general it's proportional to the number of words and the number of intersection points between them.", 
            "title": "Complexity"
        }, 
        {
            "location": "/Commands/#returns_4", 
            "text": "Array reply,  where the first element is the total number of results, and then pairs of document id, and a nested array of field/value.   If  NOCONTENT  was given, we return an array where the first element is the total number of results, and the rest of the members are document ids.", 
            "title": "Returns"
        }, 
        {
            "location": "/Commands/#ftdel", 
            "text": "", 
            "title": "FT.DEL"
        }, 
        {
            "location": "/Commands/#format_5", 
            "text": "FT.DEL {index} {doc_id}", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_5", 
            "text": "Delete a document from the index. Returns 1 if the document was in the index, or 0 if not.   After deletion, the document can be re-added to the index. It will get a different internal id and will be a new document from the index's POV.  NOTE : This does not actually delete the document from the index, just marks it as deleted. \nThus, deleting and re-inserting the same document over and over will inflate the index size with each re-insertion.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_5", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE  doc_id : the id of the document to be deleted. It does not actually delete the HASH key in which the document is stored. Use DEL to do that manually if needed.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#complexity_5", 
            "text": "O(1)", 
            "title": "Complexity"
        }, 
        {
            "location": "/Commands/#returns_5", 
            "text": "Integer Reply: 1 if the document was deleted, 0 if not.", 
            "title": "Returns"
        }, 
        {
            "location": "/Commands/#ftdrop", 
            "text": "", 
            "title": "FT.DROP"
        }, 
        {
            "location": "/Commands/#format_6", 
            "text": "FT.DROP {index}", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_6", 
            "text": "Deletes all the keys associated with the index.   If no other data is on the redis instance, this is equivalent to FLUSHDB, apart from the fact\nthat the index specification is not deleted.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_6", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#returns_6", 
            "text": "Status Reply: OK on success.", 
            "title": "Returns"
        }, 
        {
            "location": "/Commands/#ftoptimize", 
            "text": "Format  FT.OPTIMIZE {index}  Description  After the index is built (and doesn't need to be updated again withuot a complete rebuild)\nwe can optimize memory consumption by trimming all index buffers to their actual size.  Warning 1 : Do not run it if you intend to update your index afterward.  Warning 2 : This blocks redis for a long time. Do not run it on production instances", 
            "title": "FT.OPTIMIZE"
        }, 
        {
            "location": "/Commands/#parameters_7", 
            "text": "index : The Fulltext index name. The index must be first created with FT.CREATE", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#returns_7", 
            "text": "Integer Reply - the number of index entries optimized.", 
            "title": "Returns:"
        }, 
        {
            "location": "/Commands/#ftsuggadd", 
            "text": "", 
            "title": "FT.SUGGADD"
        }, 
        {
            "location": "/Commands/#format_7", 
            "text": "FT.SUGADD {key} {string} {score} [INCR]", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_7", 
            "text": "Add a suggestion string to an auto-complete suggestion dictionary. This is disconnected from the\nindex definitions, and leaves creating and updating suggestino dictionaries to the user.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_8", 
            "text": "key : the suggestion dictionary key.  string : the suggestion string we index  score : a floating point number of the suggestion string's weight  INCR : if set, we increment the existing entry of the suggestion by the given score, instead of replacing the score. This is useful for updating the dictionary based on user queries in real time", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#returns_8", 
            "text": "Integer Reply: the current size of the suggestion dictionary.", 
            "title": "Returns:"
        }, 
        {
            "location": "/Commands/#ftsugget", 
            "text": "", 
            "title": "FT.SUGGET"
        }, 
        {
            "location": "/Commands/#format_8", 
            "text": "FT . SUGGET   { key }   { prefix }   [ FUZZY ]   [ MAX   num ]", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_8", 
            "text": "Get completion suggestions for a prefix", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_9", 
            "text": "key : the suggestion dictionary key.  prefix : the prefix to complete on  FUZZY : if set,we do a fuzzy prefix search, including prefixes at levenshtein distance of 1 from the prefix sent  MAX num : If set, we limit the results to a maximum of  num . ( Note : The default is 5, and the number cannot be greater than 10).  WITHSCORES : If set, we also return the score of each suggestion. this can be\n  used to merge results from multiple instances", 
            "title": "Parameters:"
        }, 
        {
            "location": "/Commands/#returns_9", 
            "text": "Array Reply: a list of the top suggestions matching the prefix, optionally with score after each entry", 
            "title": "Returns:"
        }, 
        {
            "location": "/Commands/#ftsugdel", 
            "text": "", 
            "title": "FT.SUGDEL"
        }, 
        {
            "location": "/Commands/#format_9", 
            "text": "FT.SUGDEL {key} {string}", 
            "title": "Format"
        }, 
        {
            "location": "/Commands/#description_9", 
            "text": "Delete a string from a suggestion index.", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_10", 
            "text": "key : the suggestion dictionary key.  string : the string to delete", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#returns_10", 
            "text": "Integer Reply: 1 if the string was found and deleted, 0 otherwise.", 
            "title": "Returns:"
        }, 
        {
            "location": "/Commands/#ftsuglen", 
            "text": "Format  FT.SUGLEN {key}", 
            "title": "FT.SUGLEN"
        }, 
        {
            "location": "/Commands/#description_10", 
            "text": "Get the size of an autoc-complete suggestion dictionary", 
            "title": "Description"
        }, 
        {
            "location": "/Commands/#parameters_11", 
            "text": "key : the suggestion dictionary key.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Commands/#returns_11", 
            "text": "Integer Reply: the current size of the suggestion dictionary.", 
            "title": "Returns:"
        }, 
        {
            "location": "/Query_Syntax/", 
            "text": "Search Query Syntax:\n\n\nWe support a simple syntax for complex queries with the following rules:\n\n\n\n\nMulti-word phrases simply a list of tokens, e.g. \nfoo bar baz\n, and imply intersection (AND) of the terms.\n\n\nExact phrases are wrapped in quotes, e.g \n\"hello world\"\n.\n\n\nOR Unions (i.e \nword1 OR word2\n), are expressed with a pipe (\n|\n), e.g. \nhello|hallo|shalom|hola\n.\n\n\nSelection of specific fields using the syntax \n@field:hello world\n.\n\n\nAn expression in a query can be wrapped in parentheses to resolve disambiguity, e.g. \n(hello|hella) (world|werld)\n.\n\n\nCombinations of the above can be used together, e.g \nhello (world|foo) \"bar baz\" bbbb\n\n\n\n\nField modifiers\n\n\nAs of version 0.12 it is possible to specify field modifiers in the query and not just using the INFIELDS global keyword. \n\n\nPer query expression or sub expression, it is possible to specify which fields it matches, by prepending the experssion with the \n@\n symbol, the field name and a \n:\n (colon) symbol. \n\n\nIf a field modifier precedes multiple words, they are considered to be a phrase with the same modifier. \n\n\nIf a field modifier preceds an expression in parentheses, it applies only to the expression inside the parentheses.\n\n\nMultiple modifiers can be combined to create complex filtering on several fields. For example, if we have an index of car models, with a vehicle class, country of origin and engine type, we can search for SUVs made in Korea with hybrid or diesel engines - with the following query:\n\n\nFT.SEARCH cars \n@country:korea @engine:(diesel|hybrid) @class:suv\n\n\n\n\n\n\nA few examples\n\n\n\n\n\n\nSimple phrase query - hello AND world\n\n\nhello world\n\n\n\n\n\n\n\n\n\nExact phrase query - \nhello\n FOLLOWED BY \nworld\n\n\nhello world\n\n\n\n\n\n\n\n\n\n\nUnion: documents containing either \nhello\n OR \nworld\n\n\nhello|world\n\n\n\n\n\n\n\n\n\nIntersection of unions\n\n\n(hello|halo) (world|werld)\n\n\n\n\n\n\n\n\n\nUnion inside phrase\n\n\n(barack|barrack) obama\n\n\n\n\n\n\n\n\n\nExact phrase in one field, one word in aonther field:\n\n\n@title:\nbarack obama\n @job:president\n\n\n\n\n\n\n\n\n\nCombined AND, OR with field specifiers:\n\n\n@title:hello world @body:(foo bar) @category:(articles|biographies)\n\n\n\n\n\n\n\n\n\nTechnical Note\n\n\nThe query parser is built using the Lemon Parser Generator. You can see the grammar definition \nat the git repo.", 
            "title": "Query Syntax"
        }, 
        {
            "location": "/Query_Syntax/#search-query-syntax", 
            "text": "We support a simple syntax for complex queries with the following rules:   Multi-word phrases simply a list of tokens, e.g.  foo bar baz , and imply intersection (AND) of the terms.  Exact phrases are wrapped in quotes, e.g  \"hello world\" .  OR Unions (i.e  word1 OR word2 ), are expressed with a pipe ( | ), e.g.  hello|hallo|shalom|hola .  Selection of specific fields using the syntax  @field:hello world .  An expression in a query can be wrapped in parentheses to resolve disambiguity, e.g.  (hello|hella) (world|werld) .  Combinations of the above can be used together, e.g  hello (world|foo) \"bar baz\" bbbb", 
            "title": "Search Query Syntax:"
        }, 
        {
            "location": "/Query_Syntax/#field-modifiers", 
            "text": "As of version 0.12 it is possible to specify field modifiers in the query and not just using the INFIELDS global keyword.   Per query expression or sub expression, it is possible to specify which fields it matches, by prepending the experssion with the  @  symbol, the field name and a  :  (colon) symbol.   If a field modifier precedes multiple words, they are considered to be a phrase with the same modifier.   If a field modifier preceds an expression in parentheses, it applies only to the expression inside the parentheses.  Multiple modifiers can be combined to create complex filtering on several fields. For example, if we have an index of car models, with a vehicle class, country of origin and engine type, we can search for SUVs made in Korea with hybrid or diesel engines - with the following query:  FT.SEARCH cars  @country:korea @engine:(diesel|hybrid) @class:suv", 
            "title": "Field modifiers"
        }, 
        {
            "location": "/Query_Syntax/#a-few-examples", 
            "text": "Simple phrase query - hello AND world  hello world    Exact phrase query -  hello  FOLLOWED BY  world  hello world     Union: documents containing either  hello  OR  world  hello|world    Intersection of unions  (hello|halo) (world|werld)    Union inside phrase  (barack|barrack) obama    Exact phrase in one field, one word in aonther field:  @title: barack obama  @job:president    Combined AND, OR with field specifiers:  @title:hello world @body:(foo bar) @category:(articles|biographies)", 
            "title": "A few examples"
        }, 
        {
            "location": "/Query_Syntax/#technical-note", 
            "text": "The query parser is built using the Lemon Parser Generator. You can see the grammar definition  at the git repo.", 
            "title": "Technical Note"
        }, 
        {
            "location": "/Extensions/", 
            "text": "Extending RediSearch\n\n\nRediSearch supports an extension mechanism, much like Redis supports modules. The API is very minimal at the moment, and it does not yet support dynamic loading of extensions in run-time. Instead, extensions must be written in C and compiled into the engine when building it.\n\n\nThere are two kinds of extension APIs at the moment: \n\n\n\n\nQuery Expanders\n, whose role is to expand query tokens (i.e. stemmers).\n\n\nScoring Funtions\n, whose role is to rank search results in query time.\n\n\n\n\nRegistering Extensions\n\n\nCurrently there is no dynamic linking of extensions and they need to be compiled into the engine. However, the API is already geared for easy registration of run-time extensions. \n\n\nThe entry point is a function receiving an \nRSExtensionCtx\n object, that contains functions for registering the expanders/scorers. \n\n\nRight now, it is necessary to call these init functions explicitly in \nmodule.c\n, but in the future this will be atuomated.\n\n\nHere is an example of an extension initialization function:\n\n\n#include\n \nredisearch.h\n //must be in the include path\n\n\n\nint\n \nMyExtensionInit\n(\nRSExtensionCtx\n \n*\nctx\n)\n \n{\n\n\n  \n/* Register  a scoring function with an alias my_scorer and no special private data and free function */\n\n  \nif\n \n(\nctx\n-\nRegisterScoringFunction\n(\nmy_scorer\n,\n \nMyCustomScorer\n,\n \nNULL\n,\n \nNULL\n)\n \n==\n \nREDISEARCH_ERR\n)\n \n{\n\n    \nreturn\n \nREDISEARCH_ERR\n;\n\n  \n}\n\n\n  \n/* Register a query expander  */\n\n  \nif\n \n(\nctx\n-\nRegisterQueryExpander\n(\nmy_expander\n,\n \nMyExpander\n,\n \nNULL\n,\n \nNULL\n)\n \n==\n\n      \nREDISEARCH_ERR\n)\n \n{\n\n    \nreturn\n \nREDISEARCH_ERR\n;\n\n  \n}\n\n\n  \nreturn\n \nREDISEARCH_OK\n;\n\n\n}\n\n\n\n\n\n\nCalling your custom functions\n\n\nWhen performing a query, you can tell RediSearch to use your scorers or expanders by specifing the SCORER or EXPANDER arguments, with the given alias.\ne.g.:\n\n\nFT.SEARCH my_index \nfoo bar\n EXPANDER my_expander SCORER my_scorer\n\n\n\n\n\nNOTE\n: Expander and scorer aliases are \ncase sensitive\n.\n\n\nThe Query Expander API\n\n\nAt the moment, we only support basic query expansion, one token at a time. An expander can decide to expand any given token with as many tokens it wishes, that will be Union-merged in query time.\n\n\nThe API for an expander is the following:\n\n\n#include\n \nredisearch.h\n //must be in the include path\n\n\n\nvoid\n \nMyQueryExpander\n(\nRSQueryExpanderCtx\n \n*\nctx\n,\n \nRSToken\n \n*\ntoken\n)\n \n{\n\n    \n...\n\n\n}\n\n\n\n\n\n\nRSQueryExpanderCtx\n\n\nRSQueryExpanderCtx is a context that contains private data of the extension, and a callback method to expand the query. It is defined as:\n\n\ntypedef\n \nstruct\n \nRSQueryExpanderCtx\n \n{\n\n\n  \n/* Opaque query object used internally by the engine, and should not be accessed */\n\n  \nstruct\n \nRSQuery\n \n*\nquery\n;\n\n\n  \n/* Opaque query node object used internally by the engine, and should not be accessed */\n\n  \nstruct\n \nRSQueryNode\n \n**\ncurrentNode\n;\n\n\n  \n/* Private data of the extension, set on extension initialization */\n\n  \nvoid\n \n*\nprivdata\n;\n\n\n  \n/* The language of the query, defaults to \nenglish\n */\n\n  \nconst\n \nchar\n \n*\nlanguage\n;\n\n\n  \n/* ExpandToken allows the user to add an expansion of the token in the query, that will be\n\n\n   * union-merged with the given token in query time. str is the expanded string, len is its length,\n\n\n   * and flags is a 32 bit flag mask that can be used by the extension to set private information on\n\n\n   * the token */\n\n  \nvoid\n \n(\n*\nExpandToken\n)(\nstruct\n \nRSQueryExpanderCtx\n \n*\nctx\n,\n \nconst\n \nchar\n \n*\nstr\n,\n \nsize_t\n \nlen\n,\n\n                      \nRSTokenFlags\n \nflags\n);\n\n\n  \n/* SetPayload allows the query expander to set GLOBAL payload on the query (not unique per token)\n\n\n   */\n\n  \nvoid\n \n(\n*\nSetPayload\n)(\nstruct\n \nRSQueryExpanderCtx\n \n*\nctx\n,\n \nRSPayload\n \npayload\n);\n\n\n\n}\n \nRSQueryExpanderCtx\n;\n\n\n\n\n\n\nRSToken\n\n\nRSToken represents a single query token to be expanded, and is defined as:\n\n\n/* A token in the query. The expanders receive query tokens and can expand the query with more query\n\n\n * tokens */\n\n\ntypedef\n \nstruct\n \n{\n\n  \n/* The token string - which may or may not be NULL terminated */\n\n  \nconst\n \nchar\n \n*\nstr\n;\n\n  \n/* The token length */\n\n  \nsize_t\n \nlen\n;\n\n\n  \n/* 1 if the token is the result of query expansion */\n\n  \nuint8_t\n \nexpanded\n:\n1\n;\n\n\n  \n/* Extension specific token flags that can be examined later by the scoring function */\n\n  \nRSTokenFlags\n \nflags\n;\n\n\n}\n \nRSToken\n;\n\n\n\n\n\n\nThe Scoring Function API\n\n\nA scoring function receives each document being evaluated by the query, for final ranking. \nIt has access to all the query terms that brought up the document,and to metadata about the\ndocument such as its a-priory score, length, etc.\n\n\nSince the scoring function is evaluated per each document, potentially millions of times, and since\nredis is single threaded - it is important that it works as fast as possible and be heavily optimized. \n\n\nA scoring function is applied to each potential result (per document) and is implemented with the following signature:\n\n\ndouble\n \nMyScoringFunction\n(\nRSScoringFunctionCtx\n \n*\nctx\n,\n \nRSIndexResult\n \n*\nres\n,\n\n                                    \nRSDocumentMetadata\n \n*\ndmd\n,\n \ndouble\n \nminScore\n);\n\n\n\n\n\n\nRSScoringFunctionCtx is a context that implements some helper methods. \n\n\nRSIndexResult is the result information - containing the document id, frequency, terms and offsets. \n\n\nRSDocumentMetadata is an object holding global information about the document, such as its a-priory score. \n\n\nminSocre is the minimal score that will yield a result that will be relevant to the search. It can be used to stop processing mid-way of before we even start.\n\n\nThe return value of the function is double representing the final score of the result. Returning 0 filters the result out automatically, thus a scoring function can act as a filter function as well.\n\n\nRSScoringFunctionCtx\n\n\nThis is an object containing the following members:\n\n\n\n\nvoid *privdata\n: a pointer to an object set by the extension on initialization time.\n\n\nRSPayload payload\n: A Payload object set either by the query expander or the client.\n\n\nint GetSlop(RSIndexResult *res)\n: A callback method that yields the total minimal distance between the query terms. This can be used to prefer results where the \"slop\" is smaller and the terms are nearer to each other.\n\n\n\n\nRSIndexResult\n\n\nThis is an object holding the information about the current result in the index, which is an aggregate of all the terms that resulted in the current document being considered a valid result.\n\n\nSee redisearch.h for details\n\n\nRSDocumentMetadata\n\n\nThis is an object describing global information, unrelated to the current query, about the document being evaluated by the scoring function. \n\n\nExample Query Expander\n\n\nThis example query expander expands each token with the the term foo:\n\n\n#include\n \nredisearch.h\n //must be in the include path\n\n\n\nvoid\n \nDummyExpander\n(\nRSQueryExpanderCtx\n \n*\nctx\n,\n \nRSToken\n \n*\ntoken\n)\n \n{\n\n    \nctx\n-\nExpandToken\n(\nctx\n,\n \nstrdup\n(\nfoo\n),\n \nstrlen\n(\nfoo\n),\n \n0x1337\n);\n  \n\n}\n\n\n\n\n\n\nExample Scoring Function\n\n\nThis is an actual scoring function, calculating TF-IDF for the document, multiplying that by the document score, and dividing that by the slop:\n\n\n#include\n \nredisearch.h\n //must be in the include path\n\n\n\ndouble\n \nTFIDFScorer\n(\nRSScoringFunctionCtx\n \n*\nctx\n,\n \nRSIndexResult\n \n*\nh\n,\n \nRSDocumentMetadata\n \n*\ndmd\n,\n\n                   \ndouble\n \nminScore\n)\n \n{\n\n  \n// no need to evaluate documents with score 0 \n\n  \nif\n \n(\ndmd\n-\nscore\n \n==\n \n0\n)\n \nreturn\n \n0\n;\n\n\n  \n// calculate sum(tf-idf) for each term in the result\n\n  \ndouble\n \ntfidf\n \n=\n \n0\n;\n\n  \nfor\n \n(\nint\n \ni\n \n=\n \n0\n;\n \ni\n \n \nh\n-\nnumRecords\n;\n \ni\n++\n)\n \n{\n\n    \n// take the term frequency and multiply by the term IDF, add that to the total\n\n    \ntfidf\n \n+=\n \n(\nfloat\n)\nh\n-\nrecords\n[\ni\n].\nfreq\n \n*\n \n(\nh\n-\nrecords\n[\ni\n].\nterm\n \n?\n \nh\n-\nrecords\n[\ni\n].\nterm\n-\nidf\n \n:\n \n0\n);\n\n  \n}\n\n  \n// normalize by the maximal frequency of any term in the document   \n\n  \ntfidf\n \n/=\n  \n(\ndouble\n)\ndmd\n-\nmaxFreq\n;\n\n\n  \n// multiply by the document score (between 0 and 1)\n\n  \ntfidf\n \n*=\n \ndmd\n-\nscore\n;\n\n\n  \n// no need to factor the slop if tfidf is already below minimal score\n\n  \nif\n \n(\ntfidf\n \n \nminScore\n)\n \n{\n\n    \nreturn\n \n0\n;\n\n  \n}\n\n\n  \n// get the slop and divide the result by it, making sure we prefer results with closer terms\n\n  \ntfidf\n \n/=\n \n(\ndouble\n)\nctx\n-\nGetSlop\n(\nh\n);\n\n\n  \nreturn\n \ntfidf\n;\n\n\n}", 
            "title": "Extension API"
        }, 
        {
            "location": "/Extensions/#extending-redisearch", 
            "text": "RediSearch supports an extension mechanism, much like Redis supports modules. The API is very minimal at the moment, and it does not yet support dynamic loading of extensions in run-time. Instead, extensions must be written in C and compiled into the engine when building it.  There are two kinds of extension APIs at the moment:    Query Expanders , whose role is to expand query tokens (i.e. stemmers).  Scoring Funtions , whose role is to rank search results in query time.", 
            "title": "Extending RediSearch"
        }, 
        {
            "location": "/Extensions/#registering-extensions", 
            "text": "Currently there is no dynamic linking of extensions and they need to be compiled into the engine. However, the API is already geared for easy registration of run-time extensions.   The entry point is a function receiving an  RSExtensionCtx  object, that contains functions for registering the expanders/scorers.   Right now, it is necessary to call these init functions explicitly in  module.c , but in the future this will be atuomated.  Here is an example of an extension initialization function:  #include   redisearch.h  //must be in the include path  int   MyExtensionInit ( RSExtensionCtx   * ctx )   { \n\n   /* Register  a scoring function with an alias my_scorer and no special private data and free function */ \n   if   ( ctx - RegisterScoringFunction ( my_scorer ,   MyCustomScorer ,   NULL ,   NULL )   ==   REDISEARCH_ERR )   { \n     return   REDISEARCH_ERR ; \n   } \n\n   /* Register a query expander  */ \n   if   ( ctx - RegisterQueryExpander ( my_expander ,   MyExpander ,   NULL ,   NULL )   == \n       REDISEARCH_ERR )   { \n     return   REDISEARCH_ERR ; \n   } \n\n   return   REDISEARCH_OK ;  }", 
            "title": "Registering Extensions"
        }, 
        {
            "location": "/Extensions/#calling-your-custom-functions", 
            "text": "When performing a query, you can tell RediSearch to use your scorers or expanders by specifing the SCORER or EXPANDER arguments, with the given alias.\ne.g.:  FT.SEARCH my_index  foo bar  EXPANDER my_expander SCORER my_scorer  NOTE : Expander and scorer aliases are  case sensitive .", 
            "title": "Calling your custom functions"
        }, 
        {
            "location": "/Extensions/#the-query-expander-api", 
            "text": "At the moment, we only support basic query expansion, one token at a time. An expander can decide to expand any given token with as many tokens it wishes, that will be Union-merged in query time.  The API for an expander is the following:  #include   redisearch.h  //must be in the include path  void   MyQueryExpander ( RSQueryExpanderCtx   * ctx ,   RSToken   * token )   { \n     ...  }", 
            "title": "The Query Expander API"
        }, 
        {
            "location": "/Extensions/#rsqueryexpanderctx", 
            "text": "RSQueryExpanderCtx is a context that contains private data of the extension, and a callback method to expand the query. It is defined as:  typedef   struct   RSQueryExpanderCtx   { \n\n   /* Opaque query object used internally by the engine, and should not be accessed */ \n   struct   RSQuery   * query ; \n\n   /* Opaque query node object used internally by the engine, and should not be accessed */ \n   struct   RSQueryNode   ** currentNode ; \n\n   /* Private data of the extension, set on extension initialization */ \n   void   * privdata ; \n\n   /* The language of the query, defaults to  english  */ \n   const   char   * language ; \n\n   /* ExpandToken allows the user to add an expansion of the token in the query, that will be     * union-merged with the given token in query time. str is the expanded string, len is its length,     * and flags is a 32 bit flag mask that can be used by the extension to set private information on     * the token */ \n   void   ( * ExpandToken )( struct   RSQueryExpanderCtx   * ctx ,   const   char   * str ,   size_t   len , \n                       RSTokenFlags   flags ); \n\n   /* SetPayload allows the query expander to set GLOBAL payload on the query (not unique per token)     */ \n   void   ( * SetPayload )( struct   RSQueryExpanderCtx   * ctx ,   RSPayload   payload );  }   RSQueryExpanderCtx ;", 
            "title": "RSQueryExpanderCtx"
        }, 
        {
            "location": "/Extensions/#rstoken", 
            "text": "RSToken represents a single query token to be expanded, and is defined as:  /* A token in the query. The expanders receive query tokens and can expand the query with more query   * tokens */  typedef   struct   { \n   /* The token string - which may or may not be NULL terminated */ \n   const   char   * str ; \n   /* The token length */ \n   size_t   len ; \n\n   /* 1 if the token is the result of query expansion */ \n   uint8_t   expanded : 1 ; \n\n   /* Extension specific token flags that can be examined later by the scoring function */ \n   RSTokenFlags   flags ;  }   RSToken ;", 
            "title": "RSToken"
        }, 
        {
            "location": "/Extensions/#the-scoring-function-api", 
            "text": "A scoring function receives each document being evaluated by the query, for final ranking. \nIt has access to all the query terms that brought up the document,and to metadata about the\ndocument such as its a-priory score, length, etc.  Since the scoring function is evaluated per each document, potentially millions of times, and since\nredis is single threaded - it is important that it works as fast as possible and be heavily optimized.   A scoring function is applied to each potential result (per document) and is implemented with the following signature:  double   MyScoringFunction ( RSScoringFunctionCtx   * ctx ,   RSIndexResult   * res , \n                                     RSDocumentMetadata   * dmd ,   double   minScore );   RSScoringFunctionCtx is a context that implements some helper methods.   RSIndexResult is the result information - containing the document id, frequency, terms and offsets.   RSDocumentMetadata is an object holding global information about the document, such as its a-priory score.   minSocre is the minimal score that will yield a result that will be relevant to the search. It can be used to stop processing mid-way of before we even start.  The return value of the function is double representing the final score of the result. Returning 0 filters the result out automatically, thus a scoring function can act as a filter function as well.", 
            "title": "The Scoring Function API"
        }, 
        {
            "location": "/Extensions/#rsscoringfunctionctx", 
            "text": "This is an object containing the following members:   void *privdata : a pointer to an object set by the extension on initialization time.  RSPayload payload : A Payload object set either by the query expander or the client.  int GetSlop(RSIndexResult *res) : A callback method that yields the total minimal distance between the query terms. This can be used to prefer results where the \"slop\" is smaller and the terms are nearer to each other.", 
            "title": "RSScoringFunctionCtx"
        }, 
        {
            "location": "/Extensions/#rsindexresult", 
            "text": "This is an object holding the information about the current result in the index, which is an aggregate of all the terms that resulted in the current document being considered a valid result.  See redisearch.h for details", 
            "title": "RSIndexResult"
        }, 
        {
            "location": "/Extensions/#rsdocumentmetadata", 
            "text": "This is an object describing global information, unrelated to the current query, about the document being evaluated by the scoring function.", 
            "title": "RSDocumentMetadata"
        }, 
        {
            "location": "/Extensions/#example-query-expander", 
            "text": "This example query expander expands each token with the the term foo:  #include   redisearch.h  //must be in the include path  void   DummyExpander ( RSQueryExpanderCtx   * ctx ,   RSToken   * token )   { \n     ctx - ExpandToken ( ctx ,   strdup ( foo ),   strlen ( foo ),   0x1337 );    }", 
            "title": "Example Query Expander"
        }, 
        {
            "location": "/Extensions/#example-scoring-function", 
            "text": "This is an actual scoring function, calculating TF-IDF for the document, multiplying that by the document score, and dividing that by the slop:  #include   redisearch.h  //must be in the include path  double   TFIDFScorer ( RSScoringFunctionCtx   * ctx ,   RSIndexResult   * h ,   RSDocumentMetadata   * dmd , \n                    double   minScore )   { \n   // no need to evaluate documents with score 0  \n   if   ( dmd - score   ==   0 )   return   0 ; \n\n   // calculate sum(tf-idf) for each term in the result \n   double   tfidf   =   0 ; \n   for   ( int   i   =   0 ;   i     h - numRecords ;   i ++ )   { \n     // take the term frequency and multiply by the term IDF, add that to the total \n     tfidf   +=   ( float ) h - records [ i ]. freq   *   ( h - records [ i ]. term   ?   h - records [ i ]. term - idf   :   0 ); \n   } \n   // normalize by the maximal frequency of any term in the document    \n   tfidf   /=    ( double ) dmd - maxFreq ; \n\n   // multiply by the document score (between 0 and 1) \n   tfidf   *=   dmd - score ; \n\n   // no need to factor the slop if tfidf is already below minimal score \n   if   ( tfidf     minScore )   { \n     return   0 ; \n   } \n\n   // get the slop and divide the result by it, making sure we prefer results with closer terms \n   tfidf   /=   ( double ) ctx - GetSlop ( h ); \n\n   return   tfidf ;  }", 
            "title": "Example Scoring Function"
        }, 
        {
            "location": "/Stemming/", 
            "text": "Stemming Support\n\n\nRediSearch supports stemming - that is adding the base form of a word to the index. This allows \nthe query for \"going\" to also return results for \"go\" and \"gone\", for example. \n\n\nThe current stemming support is based on the Snowball stemmer library, which supports most European\nlanguages, as well as Arabic and other. We hope to include more languages soon (if you need a specicif\nlangauge support, please open an issue). \n\n\nFor further details see the \nSnowball Stemmer website\n.\n\n\nSupported languages:\n\n\nThe following languages are supported, and can be passed to the engine \nwhen indexing or querying, with lowercase letters:\n\n\n\n\narabic\n\n\ndanish\n\n\ndutch\n\n\nenglish\n\n\nfinnish\n\n\nfrench\n\n\ngerman\n\n\nhungarian\n\n\nitalian\n\n\nnorwegian\n\n\nportuguese\n\n\nromanian\n\n\nrussian\n\n\nspanish\n\n\nswedish\n\n\ntamil\n\n\nturkish", 
            "title": "Stemming Support"
        }, 
        {
            "location": "/Stemming/#stemming-support", 
            "text": "RediSearch supports stemming - that is adding the base form of a word to the index. This allows \nthe query for \"going\" to also return results for \"go\" and \"gone\", for example.   The current stemming support is based on the Snowball stemmer library, which supports most European\nlanguages, as well as Arabic and other. We hope to include more languages soon (if you need a specicif\nlangauge support, please open an issue).   For further details see the  Snowball Stemmer website .", 
            "title": "Stemming Support"
        }, 
        {
            "location": "/Stemming/#supported-languages", 
            "text": "The following languages are supported, and can be passed to the engine \nwhen indexing or querying, with lowercase letters:   arabic  danish  dutch  english  finnish  french  german  hungarian  italian  norwegian  portuguese  romanian  russian  spanish  swedish  tamil  turkish", 
            "title": "Supported languages:"
        }, 
        {
            "location": "/python_client/", 
            "text": "Package redisearch Documentation\n\n\nOverview\n\n\nredisearch-py\n is a python search engine library that utilizes the RediSearch Redis Module API.\n\n\nIt is the \"official\" client of redisearch, and should be regarded as its canonical client implementation.\n\n\nThe source code can be found at \nhttp://github.com/RedisLabs/redisearch-py\n\n\nExample: Using the Python Client\n\n\nfrom\n \nredisearch\n \nimport\n \nClient\n,\n \nTextField\n,\n \nNumericField\n\n\n\n# Creating a client with a given index name\n\n\nclient\n \n=\n \nClient\n(\nmyIndex\n)\n\n\n\n# Creating the index definition and schema\n\n\nclient\n.\ncreate_index\n([\nTextField\n(\ntitle\n,\n \nweight\n=\n5.0\n),\n \nTextField\n(\nbody\n)])\n\n\n\n# Indexing a document\n\n\nclient\n.\nadd_document\n(\ndoc1\n,\n \ntitle\n \n=\n \nRediSearch\n,\n \nbody\n \n=\n \nRedisearch impements a search engine on top of redis\n)\n\n\n\n# Simple search\n\n\nres\n \n=\n \nclient\n.\nsearch\n(\nsearch engine\n)\n\n\n\n# the result has the total number of results, and a list of documents\n\n\nprint\n \nres\n.\ntotal\n \n# \n1\n\n\nprint\n \nres\n.\ndocs\n[\n0\n]\n.\ntitle\n \n\n\n# Searching with snippets\n\n\nres\n \n=\n \nclient\n.\nsearch\n(\nsearch engine\n,\n \nsnippet_sizes\n \n=\n \n{\nbody\n:\n \n50\n})\n\n\n\n# Searching with complext parameters:\n\n\nq\n \n=\n \nQuery\n(\nsearch engine\n)\n.\nverbatim\n()\n.\nno_content\n()\n.\npaging\n(\n0\n,\n5\n)\n\n\nres\n \n=\n \nclient\n.\nsearch\n(\nq\n)\n\n\n\n\n\n\nExample: Using the Auto Completer Client:\n\n\n# Using the auto-completer\n\n\nac\n \n=\n \nAutoCompleter\n(\nac\n)\n\n\n\n# Adding some terms\n\n\nac\n.\nadd_suggestions\n(\nSuggestion\n(\nfoo\n,\n \n5.0\n),\n \nSuggestion\n(\nbar\n,\n \n1.0\n))\n\n\n\n# Getting suggestions\n\n\nsuggs\n \n=\n \nac\n.\nget_suggestions\n(\ngoo\n)\n \n# returns nothing\n\n\n\nsuggs\n \n=\n \nac\n.\nget_suggestions\n(\ngoo\n,\n \nfuzzy\n \n=\n \nTrue\n)\n \n# returns [\nfoo\n]\n\n\n\n\n\n\nInstalling\n\n\n\n\n\n\nInstall redis 4.0 RC2 or above\n\n\n\n\n\n\nInstall RediSearch\n\n\n\n\n\n\nInstall the python client\n\n\n\n\n\n\n$ pip install redisearch\n\n\n\n\n\nClass AutoCompleter\n\n\nA client to RediSearch's AutoCompleter API\n\n\nIt provides prefix searches with optionally fuzzy matching of prefixes    \n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nkey\n,\n \nhost\n=\nlocalhost\n,\n \nport\n=\n6379\n,\n \nconn\n=\nNone\n)\n\n\n\n\n\n\nCreate a new AutoCompleter client for the given key, and optional host and port\n\n\nIf conn is not None, we employ an already existing redis connection\n\n\nadd_suggestions\n\n\ndef\n \nadd_suggestions\n(\nself\n,\n \n*\nsuggestions\n,\n \n**\nkwargs\n)\n\n\n\n\n\n\nAdd suggestion terms to the AutoCompleter engine. Each suggestion has a score and string.\n\n\nIf kwargs['increment'] is true and the terms are already in the server's dictionary, we increment their scores \n\n\ndelete\n\n\ndef\n \ndelete\n(\nself\n,\n \nstring\n)\n\n\n\n\n\n\nDelete a string from the AutoCompleter index.\nReturns 1 if the string was found and deleted, 0 otherwise\n\n\nget_suggestions\n\n\ndef\n \nget_suggestions\n(\nself\n,\n \nprefix\n,\n \nfuzzy\n=\nFalse\n,\n \nnum\n=\n10\n,\n \nwith_scores\n=\nFalse\n)\n\n\n\n\n\n\nGet a list of suggestions from the AutoCompleter, for a given prefix\n\n\nParameters:\n\n\n\n\nprefix\n: the prefix we are searching. \nMust be valid ascii or utf-8\n\n\nfuzzy\n: If set to true, the prefix search is done in fuzzy mode. \n    \nNOTE\n: Running fuzzy searches on short (\n3 letters) prefixes can be very slow, and even scan the entire index.\n\n\nwith_scores\n: if set to true, we also return the (refactored) score of each suggestion. \n  This is normally not needed, and is NOT the original score inserted into the index\n\n\nnum\n: The maximum number of results we return. Note that we might return less. The algorithm trims irrelevant suggestions.\n\n\n\n\nReturns a list of Suggestion objects. If with_scores was False, the score of all suggestions is 1.\n\n\nlen\n\n\ndef\n \nlen\n(\nself\n)\n\n\n\n\n\n\nReturn the number of entries in the AutoCompleter index\n\n\nClass Client\n\n\nA client for the RediSearch module. \nIt abstracts the API of the module and lets you just use the engine \n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nindex_name\n,\n \nhost\n=\nlocalhost\n,\n \nport\n=\n6379\n,\n \nconn\n=\nNone\n)\n\n\n\n\n\n\nCreate a new Client for the given index_name, and optional host and port\n\n\nIf conn is not None, we employ an already existing redis connection\n\n\nadd_document\n\n\ndef\n \nadd_document\n(\nself\n,\n \ndoc_id\n,\n \nnosave\n=\nFalse\n,\n \nscore\n=\n1.0\n,\n \npayload\n=\nNone\n,\n \nreplace\n=\nFalse\n,\n \n**\nfields\n)\n\n\n\n\n\n\nAdd a single document to the index.\n\n\nParameters\n\n\n\n\ndoc_id\n: the id of the saved document.\n\n\nnosave\n: if set to true, we just index the document, and don't save a copy of it. This means that searches will just return ids.\n\n\nscore\n: the document ranking, between 0.0 and 1.0 \n\n\npayload\n: optional inner-index payload we can save for fast access in scoring functions\n\n\nreplace\n: if True, and the document already is in the index, we perform an update and reindex the document\n\n\nfields\n kwargs dictionary of the document fields to be saved and/or indexed. \n             NOTE: Geo points shoule be encoded as strings of \"lon,lat\"\n\n\n\n\nbatch_indexer\n\n\ndef\n \nbatch_indexer\n(\nself\n,\n \nchunk_size\n=\n100\n)\n\n\n\n\n\n\nCreate a new batch indexer from the client with a given chunk size\n\n\ncreate_index\n\n\ndef\n \ncreate_index\n(\nself\n,\n \nfields\n,\n \nno_term_offsets\n=\nFalse\n,\n \nno_field_flags\n=\nFalse\n,\n \nno_score_indexes\n=\nFalse\n)\n\n\n\n\n\n\nCreate the search index. Creating an existing index juts updates its properties\n\n\nParameters:\n\n\n\n\nfields\n: a list of TextField or NumericField objects\n\n\nno_term_offsets\n: If true, we will not save term offsets in the index\n\n\nno_field_flags\n: If true, we will not save field flags that allow searching in specific fields\n\n\nno_score_indexes\n: If true, we will not save optimized top score indexes for single word queries\n\n\n\n\ndrop_index\n\n\ndef\n \ndrop_index\n(\nself\n)\n\n\n\n\n\n\nDrop the index if it exists\n\n\ninfo\n\n\ndef\n \ninfo\n(\nself\n)\n\n\n\n\n\n\nGet info an stats about the the current index, including the number of documents, memory consumption, etc\n\n\nload_document\n\n\ndef\n \nload_document\n(\nself\n,\n \nid\n)\n\n\n\n\n\n\nLoad a single document by id\n\n\nsearch\n\n\ndef\n \nsearch\n(\nself\n,\n \nquery\n,\n \nsnippet_sizes\n=\nNone\n)\n\n\n\n\n\n\nSearch the index for a given query, and return a result of documents\n\n\nParameters\n\n\n\n\nquery\n: the search query. Either a text for simple queries with default parameters, or a Query object for complex queries.\n             See RediSearch's documentation on query format\n\n\nsnippet_sizes\n: A dictionary of {field: snippet_size} used to trim and format the result. e.g.e {'body': 500}\n\n\n\n\nClass BatchIndexer\n\n\nA batch indexer allows you to automatically batch \ndocument indexeing in pipelines, flushing it every N documents. \n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nclient\n,\n \nchunk_size\n=\n1000\n)\n\n\n\n\n\n\nadd_document\n\n\ndef\n \nadd_document\n(\nself\n,\n \ndoc_id\n,\n \nnosave\n=\nFalse\n,\n \nscore\n=\n1.0\n,\n \npayload\n=\nNone\n,\n \nreplace\n=\nFalse\n,\n \n**\nfields\n)\n\n\n\n\n\n\nAdd a document to the batch query\n\n\ncommit\n\n\ndef\n \ncommit\n(\nself\n)\n\n\n\n\n\n\nManually commit and flush the batch indexing query\n\n\nClass Document\n\n\nRepresents a single document in a result set \n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nid\n,\n \npayload\n=\nNone\n,\n \n**\nfields\n)\n\n\n\n\n\n\nsnippetize\n\n\ndef\n \nsnippetize\n(\nself\n,\n \nfield\n,\n \nsize\n=\n500\n,\n \nbold_tokens\n=\n())\n\n\n\n\n\n\nCreate a shortened snippet from the document's content \n:param size: the szie of the snippet in characters. It might be a bit longer or shorter\n:param boldTokens: a list of tokens we want to make bold (basically the query terms)\n\n\nClass GeoField\n\n\nGeoField is used to define a geo-indexing field in a schema defintion\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nname\n)\n\n\n\n\n\n\nredis_args\n\n\ndef\n \nredis_args\n(\nself\n)\n\n\n\n\n\n\nClass GeoFilter\n\n\nNone\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nfield\n,\n \nlon\n,\n \nlat\n,\n \nradius\n,\n \nunit\n=\nkm\n)\n\n\n\n\n\n\nClass NumericField\n\n\nNumericField is used to define a numeric field in a schema defintion\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nname\n)\n\n\n\n\n\n\nredis_args\n\n\ndef\n \nredis_args\n(\nself\n)\n\n\n\n\n\n\nClass NumericFilter\n\n\nNone\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nfield\n,\n \nminval\n,\n \nmaxval\n,\n \nminExclusive\n=\nFalse\n,\n \nmaxExclusive\n=\nFalse\n)\n\n\n\n\n\n\nClass Query\n\n\nQuery is used to build complex queries that have more parameters than just the query string.\nThe query string is set in the constructor, and other options have setter functions.\n\n\nThe setter functions return the query object, so they can be chained, \ni.e. \nQuery(\"foo\").verbatim().filter(...)\n etc.\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nquery_string\n)\n\n\n\n\n\n\nCreate a new query object. \n\n\nThe query string is set in the constructor, and other options have setter functions.\n\n\nadd_filter\n\n\ndef\n \nadd_filter\n(\nself\n,\n \nflt\n)\n\n\n\n\n\n\nAdd a numeric or geo filter to the query. \n\nCurrently only one of each filter is supported by the engine\n\n\n\n\nflt\n: A NumericFilter or GeoFilter object, used on a corresponding field\n\n\n\n\nget_args\n\n\ndef\n \nget_args\n(\nself\n)\n\n\n\n\n\n\nFormat the redis arguments for this query and return them\n\n\nin_order\n\n\ndef\n \nin_order\n(\nself\n)\n\n\n\n\n\n\nMatch only documents where the query terms appear in the same order in the document.\ni.e. for the query 'hello world', we do not match 'world hello'\n\n\nlimit_fields\n\n\ndef\n \nlimit_fields\n(\nself\n,\n \n*\nfields\n)\n\n\n\n\n\n\nLimit the search to specific TEXT fields only\n\n\n\n\nfields\n: A list of strings, case sensitive field names from the defined schema\n\n\n\n\nlimit_ids\n\n\ndef\n \nlimit_ids\n(\nself\n,\n \n*\nids\n)\n\n\n\n\n\n\nLimit the results to a specific set of pre-known document ids of any length\n\n\nno_content\n\n\ndef\n \nno_content\n(\nself\n)\n\n\n\n\n\n\nSet the query to only return ids and not the document content\n\n\nno_stopwords\n\n\ndef\n \nno_stopwords\n(\nself\n)\n\n\n\n\n\n\nPrevent the query from being filtered for stopwords. \nOnly useful in very big queries that you are certain contain no stopwords.\n\n\npaging\n\n\ndef\n \npaging\n(\nself\n,\n \noffset\n,\n \nnum\n)\n\n\n\n\n\n\nSet the paging for the query (defaults to 0..10).\n\n\n\n\noffset\n: Paging offset for the results. Defaults to 0\n\n\nnum\n: How many results do we want\n\n\n\n\nquery_string\n\n\ndef\n \nquery_string\n(\nself\n)\n\n\n\n\n\n\nReturn the query string of this query only\n\n\nslop\n\n\ndef\n \nslop\n(\nself\n,\n \nslop\n)\n\n\n\n\n\n\nAllow a masimum of N intervening non matched terms between phrase terms (0 means exact phrase)\n\n\nverbatim\n\n\ndef\n \nverbatim\n(\nself\n)\n\n\n\n\n\n\nSet the query to be verbatim, i.e. use no query expansion or stemming\n\n\nwith_payloads\n\n\ndef\n \nwith_payloads\n(\nself\n)\n\n\n\n\n\n\nAsk the engine to return document payloads\n\n\nClass Result\n\n\nRepresents the result of a search query, and has an array of Document objects\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nres\n,\n \nhascontent\n,\n \nquery_text\n,\n \nduration\n=\n0\n,\n \nsnippets\n=\nNone\n,\n \nhas_payload\n=\nFalse\n)\n\n\n\n\n\n\n\n\nsnippets\n: An optional dictionary of the form {field: snippet_size} for snippet formatting\n\n\n\n\nClass Suggestion\n\n\nRepresents a single suggestion being sent or returned from the auto complete server\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nstring\n,\n \nscore\n=\n1.0\n)\n\n\n\n\n\n\nClass TextField\n\n\nTextField is used to define a text field in a schema definition\n\n\n__init__\n\n\ndef\n \n__init__\n(\nself\n,\n \nname\n,\n \nweight\n=\n1.0\n)\n\n\n\n\n\n\nredis_args\n\n\ndef\n \nredis_args\n(\nself\n)", 
            "title": "Python API"
        }, 
        {
            "location": "/python_client/#package-redisearch-documentation", 
            "text": "", 
            "title": "Package redisearch Documentation"
        }, 
        {
            "location": "/python_client/#overview", 
            "text": "redisearch-py  is a python search engine library that utilizes the RediSearch Redis Module API.  It is the \"official\" client of redisearch, and should be regarded as its canonical client implementation.  The source code can be found at  http://github.com/RedisLabs/redisearch-py", 
            "title": "Overview"
        }, 
        {
            "location": "/python_client/#example-using-the-python-client", 
            "text": "from   redisearch   import   Client ,   TextField ,   NumericField  # Creating a client with a given index name  client   =   Client ( myIndex )  # Creating the index definition and schema  client . create_index ([ TextField ( title ,   weight = 5.0 ),   TextField ( body )])  # Indexing a document  client . add_document ( doc1 ,   title   =   RediSearch ,   body   =   Redisearch impements a search engine on top of redis )  # Simple search  res   =   client . search ( search engine )  # the result has the total number of results, and a list of documents  print   res . total   #  1  print   res . docs [ 0 ] . title   # Searching with snippets  res   =   client . search ( search engine ,   snippet_sizes   =   { body :   50 })  # Searching with complext parameters:  q   =   Query ( search engine ) . verbatim () . no_content () . paging ( 0 , 5 )  res   =   client . search ( q )", 
            "title": "Example: Using the Python Client"
        }, 
        {
            "location": "/python_client/#example-using-the-auto-completer-client", 
            "text": "# Using the auto-completer  ac   =   AutoCompleter ( ac )  # Adding some terms  ac . add_suggestions ( Suggestion ( foo ,   5.0 ),   Suggestion ( bar ,   1.0 ))  # Getting suggestions  suggs   =   ac . get_suggestions ( goo )   # returns nothing  suggs   =   ac . get_suggestions ( goo ,   fuzzy   =   True )   # returns [ foo ]", 
            "title": "Example: Using the Auto Completer Client:"
        }, 
        {
            "location": "/python_client/#installing", 
            "text": "Install redis 4.0 RC2 or above    Install RediSearch    Install the python client    $ pip install redisearch", 
            "title": "Installing"
        }, 
        {
            "location": "/python_client/#class-autocompleter", 
            "text": "A client to RediSearch's AutoCompleter API  It provides prefix searches with optionally fuzzy matching of prefixes", 
            "title": "Class AutoCompleter"
        }, 
        {
            "location": "/python_client/#9595init9595", 
            "text": "def   __init__ ( self ,   key ,   host = localhost ,   port = 6379 ,   conn = None )   Create a new AutoCompleter client for the given key, and optional host and port  If conn is not None, we employ an already existing redis connection", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#add95suggestions", 
            "text": "def   add_suggestions ( self ,   * suggestions ,   ** kwargs )   Add suggestion terms to the AutoCompleter engine. Each suggestion has a score and string.  If kwargs['increment'] is true and the terms are already in the server's dictionary, we increment their scores", 
            "title": "add_suggestions"
        }, 
        {
            "location": "/python_client/#delete", 
            "text": "def   delete ( self ,   string )   Delete a string from the AutoCompleter index.\nReturns 1 if the string was found and deleted, 0 otherwise", 
            "title": "delete"
        }, 
        {
            "location": "/python_client/#get95suggestions", 
            "text": "def   get_suggestions ( self ,   prefix ,   fuzzy = False ,   num = 10 ,   with_scores = False )   Get a list of suggestions from the AutoCompleter, for a given prefix", 
            "title": "get_suggestions"
        }, 
        {
            "location": "/python_client/#parameters", 
            "text": "prefix : the prefix we are searching.  Must be valid ascii or utf-8  fuzzy : If set to true, the prefix search is done in fuzzy mode. \n     NOTE : Running fuzzy searches on short ( 3 letters) prefixes can be very slow, and even scan the entire index.  with_scores : if set to true, we also return the (refactored) score of each suggestion. \n  This is normally not needed, and is NOT the original score inserted into the index  num : The maximum number of results we return. Note that we might return less. The algorithm trims irrelevant suggestions.   Returns a list of Suggestion objects. If with_scores was False, the score of all suggestions is 1.", 
            "title": "Parameters:"
        }, 
        {
            "location": "/python_client/#len", 
            "text": "def   len ( self )   Return the number of entries in the AutoCompleter index", 
            "title": "len"
        }, 
        {
            "location": "/python_client/#class-client", 
            "text": "A client for the RediSearch module. \nIt abstracts the API of the module and lets you just use the engine", 
            "title": "Class Client"
        }, 
        {
            "location": "/python_client/#9595init9595_1", 
            "text": "def   __init__ ( self ,   index_name ,   host = localhost ,   port = 6379 ,   conn = None )   Create a new Client for the given index_name, and optional host and port  If conn is not None, we employ an already existing redis connection", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#add95document", 
            "text": "def   add_document ( self ,   doc_id ,   nosave = False ,   score = 1.0 ,   payload = None ,   replace = False ,   ** fields )   Add a single document to the index.", 
            "title": "add_document"
        }, 
        {
            "location": "/python_client/#parameters_1", 
            "text": "doc_id : the id of the saved document.  nosave : if set to true, we just index the document, and don't save a copy of it. This means that searches will just return ids.  score : the document ranking, between 0.0 and 1.0   payload : optional inner-index payload we can save for fast access in scoring functions  replace : if True, and the document already is in the index, we perform an update and reindex the document  fields  kwargs dictionary of the document fields to be saved and/or indexed. \n             NOTE: Geo points shoule be encoded as strings of \"lon,lat\"", 
            "title": "Parameters"
        }, 
        {
            "location": "/python_client/#batch95indexer", 
            "text": "def   batch_indexer ( self ,   chunk_size = 100 )   Create a new batch indexer from the client with a given chunk size", 
            "title": "batch_indexer"
        }, 
        {
            "location": "/python_client/#create95index", 
            "text": "def   create_index ( self ,   fields ,   no_term_offsets = False ,   no_field_flags = False ,   no_score_indexes = False )   Create the search index. Creating an existing index juts updates its properties", 
            "title": "create_index"
        }, 
        {
            "location": "/python_client/#parameters_2", 
            "text": "fields : a list of TextField or NumericField objects  no_term_offsets : If true, we will not save term offsets in the index  no_field_flags : If true, we will not save field flags that allow searching in specific fields  no_score_indexes : If true, we will not save optimized top score indexes for single word queries", 
            "title": "Parameters:"
        }, 
        {
            "location": "/python_client/#drop95index", 
            "text": "def   drop_index ( self )   Drop the index if it exists", 
            "title": "drop_index"
        }, 
        {
            "location": "/python_client/#info", 
            "text": "def   info ( self )   Get info an stats about the the current index, including the number of documents, memory consumption, etc", 
            "title": "info"
        }, 
        {
            "location": "/python_client/#load95document", 
            "text": "def   load_document ( self ,   id )   Load a single document by id", 
            "title": "load_document"
        }, 
        {
            "location": "/python_client/#search", 
            "text": "def   search ( self ,   query ,   snippet_sizes = None )   Search the index for a given query, and return a result of documents", 
            "title": "search"
        }, 
        {
            "location": "/python_client/#parameters_3", 
            "text": "query : the search query. Either a text for simple queries with default parameters, or a Query object for complex queries.\n             See RediSearch's documentation on query format  snippet_sizes : A dictionary of {field: snippet_size} used to trim and format the result. e.g.e {'body': 500}", 
            "title": "Parameters"
        }, 
        {
            "location": "/python_client/#class-batchindexer", 
            "text": "A batch indexer allows you to automatically batch \ndocument indexeing in pipelines, flushing it every N documents.", 
            "title": "Class BatchIndexer"
        }, 
        {
            "location": "/python_client/#9595init9595_2", 
            "text": "def   __init__ ( self ,   client ,   chunk_size = 1000 )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#add95document_1", 
            "text": "def   add_document ( self ,   doc_id ,   nosave = False ,   score = 1.0 ,   payload = None ,   replace = False ,   ** fields )   Add a document to the batch query", 
            "title": "add_document"
        }, 
        {
            "location": "/python_client/#commit", 
            "text": "def   commit ( self )   Manually commit and flush the batch indexing query", 
            "title": "commit"
        }, 
        {
            "location": "/python_client/#class-document", 
            "text": "Represents a single document in a result set", 
            "title": "Class Document"
        }, 
        {
            "location": "/python_client/#9595init9595_3", 
            "text": "def   __init__ ( self ,   id ,   payload = None ,   ** fields )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#snippetize", 
            "text": "def   snippetize ( self ,   field ,   size = 500 ,   bold_tokens = ())   Create a shortened snippet from the document's content \n:param size: the szie of the snippet in characters. It might be a bit longer or shorter\n:param boldTokens: a list of tokens we want to make bold (basically the query terms)", 
            "title": "snippetize"
        }, 
        {
            "location": "/python_client/#class-geofield", 
            "text": "GeoField is used to define a geo-indexing field in a schema defintion", 
            "title": "Class GeoField"
        }, 
        {
            "location": "/python_client/#9595init9595_4", 
            "text": "def   __init__ ( self ,   name )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#redis95args", 
            "text": "def   redis_args ( self )", 
            "title": "redis_args"
        }, 
        {
            "location": "/python_client/#class-geofilter", 
            "text": "None", 
            "title": "Class GeoFilter"
        }, 
        {
            "location": "/python_client/#9595init9595_5", 
            "text": "def   __init__ ( self ,   field ,   lon ,   lat ,   radius ,   unit = km )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#class-numericfield", 
            "text": "NumericField is used to define a numeric field in a schema defintion", 
            "title": "Class NumericField"
        }, 
        {
            "location": "/python_client/#9595init9595_6", 
            "text": "def   __init__ ( self ,   name )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#redis95args_1", 
            "text": "def   redis_args ( self )", 
            "title": "redis_args"
        }, 
        {
            "location": "/python_client/#class-numericfilter", 
            "text": "None", 
            "title": "Class NumericFilter"
        }, 
        {
            "location": "/python_client/#9595init9595_7", 
            "text": "def   __init__ ( self ,   field ,   minval ,   maxval ,   minExclusive = False ,   maxExclusive = False )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#class-query", 
            "text": "Query is used to build complex queries that have more parameters than just the query string.\nThe query string is set in the constructor, and other options have setter functions.  The setter functions return the query object, so they can be chained, \ni.e.  Query(\"foo\").verbatim().filter(...)  etc.", 
            "title": "Class Query"
        }, 
        {
            "location": "/python_client/#9595init9595_8", 
            "text": "def   __init__ ( self ,   query_string )   Create a new query object.   The query string is set in the constructor, and other options have setter functions.", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#add95filter", 
            "text": "def   add_filter ( self ,   flt )   Add a numeric or geo filter to the query.  Currently only one of each filter is supported by the engine   flt : A NumericFilter or GeoFilter object, used on a corresponding field", 
            "title": "add_filter"
        }, 
        {
            "location": "/python_client/#get95args", 
            "text": "def   get_args ( self )   Format the redis arguments for this query and return them", 
            "title": "get_args"
        }, 
        {
            "location": "/python_client/#in95order", 
            "text": "def   in_order ( self )   Match only documents where the query terms appear in the same order in the document.\ni.e. for the query 'hello world', we do not match 'world hello'", 
            "title": "in_order"
        }, 
        {
            "location": "/python_client/#limit95fields", 
            "text": "def   limit_fields ( self ,   * fields )   Limit the search to specific TEXT fields only   fields : A list of strings, case sensitive field names from the defined schema", 
            "title": "limit_fields"
        }, 
        {
            "location": "/python_client/#limit95ids", 
            "text": "def   limit_ids ( self ,   * ids )   Limit the results to a specific set of pre-known document ids of any length", 
            "title": "limit_ids"
        }, 
        {
            "location": "/python_client/#no95content", 
            "text": "def   no_content ( self )   Set the query to only return ids and not the document content", 
            "title": "no_content"
        }, 
        {
            "location": "/python_client/#no95stopwords", 
            "text": "def   no_stopwords ( self )   Prevent the query from being filtered for stopwords. \nOnly useful in very big queries that you are certain contain no stopwords.", 
            "title": "no_stopwords"
        }, 
        {
            "location": "/python_client/#paging", 
            "text": "def   paging ( self ,   offset ,   num )   Set the paging for the query (defaults to 0..10).   offset : Paging offset for the results. Defaults to 0  num : How many results do we want", 
            "title": "paging"
        }, 
        {
            "location": "/python_client/#query95string", 
            "text": "def   query_string ( self )   Return the query string of this query only", 
            "title": "query_string"
        }, 
        {
            "location": "/python_client/#slop", 
            "text": "def   slop ( self ,   slop )   Allow a masimum of N intervening non matched terms between phrase terms (0 means exact phrase)", 
            "title": "slop"
        }, 
        {
            "location": "/python_client/#verbatim", 
            "text": "def   verbatim ( self )   Set the query to be verbatim, i.e. use no query expansion or stemming", 
            "title": "verbatim"
        }, 
        {
            "location": "/python_client/#with95payloads", 
            "text": "def   with_payloads ( self )   Ask the engine to return document payloads", 
            "title": "with_payloads"
        }, 
        {
            "location": "/python_client/#class-result", 
            "text": "Represents the result of a search query, and has an array of Document objects", 
            "title": "Class Result"
        }, 
        {
            "location": "/python_client/#9595init9595_9", 
            "text": "def   __init__ ( self ,   res ,   hascontent ,   query_text ,   duration = 0 ,   snippets = None ,   has_payload = False )    snippets : An optional dictionary of the form {field: snippet_size} for snippet formatting", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#class-suggestion", 
            "text": "Represents a single suggestion being sent or returned from the auto complete server", 
            "title": "Class Suggestion"
        }, 
        {
            "location": "/python_client/#9595init9595_10", 
            "text": "def   __init__ ( self ,   string ,   score = 1.0 )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#class-textfield", 
            "text": "TextField is used to define a text field in a schema definition", 
            "title": "Class TextField"
        }, 
        {
            "location": "/python_client/#9595init9595_11", 
            "text": "def   __init__ ( self ,   name ,   weight = 1.0 )", 
            "title": "__init__"
        }, 
        {
            "location": "/python_client/#redis95args_2", 
            "text": "def   redis_args ( self )", 
            "title": "redis_args"
        }, 
        {
            "location": "/java_client/", 
            "text": "JRediSearch - RediSearch Java Client\n\n\nhttps://github.com/RedisLabs/JRediSearch\n\n\nOverview\n\n\nJRediSearch is a Java library abstracting the API of the RediSearch Redis module, that implements a powerful in-memory search engine inside Redis. \n\n\nSee full documentation at \nhttps://github.com/RedisLabs/JRediSearch\n.\n\n\nUsage example\n\n\nInitializing the client:\n\n\nimport\n \nio.redisearch.client.Client\n;\n\n\nimport\n \nio.redisearch.Document\n;\n\n\nimport\n \nio.redisearch.SearchResult\n;\n\n\nimport\n \nio.redisearch.Query\n;\n\n\nimport\n \nio.redisearch.Schema\n;\n\n\n\n...\n\n\n\nClient\n \nclient\n \n=\n \nnew\n \nClient\n(\ntestung\n,\n \nlocalhost\n,\n \n6379\n);\n\n\n\n\n\n\nDefining a schema for an index and creating it:\n\n\nSchema\n \nsc\n \n=\n \nnew\n \nSchema\n()\n\n                \n.\naddTextField\n(\ntitle\n,\n \n5.0\n)\n\n                \n.\naddTextField\n(\nbody\n,\n \n1.0\n)\n\n                \n.\naddNumericField\n(\nprice\n);\n\n\n\nclient\n.\ncreateIndex\n(\nsc\n,\n \nClient\n.\nIndexOptions\n.\nDefault\n());\n\n\n\n\n\n\nAdding documents to the index:\n\n\nMap\nString\n,\n \nObject\n \nfields\n \n=\n \nnew\n \nHashMap\n();\n\n\nfields\n.\nput\n(\ntitle\n,\n \nhello world\n);\n\n\nfields\n.\nput\n(\nbody\n,\n \nlorem ipsum\n);\n\n\nfields\n.\nput\n(\nprice\n,\n \n1337\n);\n\n\n\nclient\n.\naddDocument\n(\ndoc1\n,\n \nfields\n);\n\n\n\n\n\n\nSearching the index:\n\n\n// Creating a complex query\n\n\nQuery\n \nq\n \n=\n \nnew\n \nQuery\n(\nhello world\n)\n\n                    \n.\naddFilter\n(\nnew\n \nQuery\n.\nNumericFilter\n(\nprice\n,\n \n0\n,\n \n1000\n))\n\n                    \n.\nlimit\n(\n0\n,\n5\n);\n\n\n\n// actual search\n\n\nSearchResult\n \nres\n \n=\n \nclient\n.\nsearch\n(\nq\n);", 
            "title": "Java API"
        }, 
        {
            "location": "/java_client/#jredisearch-redisearch-java-client", 
            "text": "https://github.com/RedisLabs/JRediSearch", 
            "title": "JRediSearch - RediSearch Java Client"
        }, 
        {
            "location": "/java_client/#overview", 
            "text": "JRediSearch is a Java library abstracting the API of the RediSearch Redis module, that implements a powerful in-memory search engine inside Redis.   See full documentation at  https://github.com/RedisLabs/JRediSearch .", 
            "title": "Overview"
        }, 
        {
            "location": "/java_client/#usage-example", 
            "text": "Initializing the client:  import   io.redisearch.client.Client ;  import   io.redisearch.Document ;  import   io.redisearch.SearchResult ;  import   io.redisearch.Query ;  import   io.redisearch.Schema ;  ...  Client   client   =   new   Client ( testung ,   localhost ,   6379 );   Defining a schema for an index and creating it:  Schema   sc   =   new   Schema () \n                 . addTextField ( title ,   5.0 ) \n                 . addTextField ( body ,   1.0 ) \n                 . addNumericField ( price );  client . createIndex ( sc ,   Client . IndexOptions . Default ());   Adding documents to the index:  Map String ,   Object   fields   =   new   HashMap ();  fields . put ( title ,   hello world );  fields . put ( body ,   lorem ipsum );  fields . put ( price ,   1337 );  client . addDocument ( doc1 ,   fields );   Searching the index:  // Creating a complex query  Query   q   =   new   Query ( hello world ) \n                     . addFilter ( new   Query . NumericFilter ( price ,   0 ,   1000 )) \n                     . limit ( 0 , 5 );  // actual search  SearchResult   res   =   client . search ( q );", 
            "title": "Usage example"
        }, 
        {
            "location": "/payloads/", 
            "text": "Document Payloads\n\n\nUsually, redisearch stores documents as HASH keys. But if you want to access some data for \naggregation or scoring functions, we might want to store that data as an inline payload. \nThis will allow us to evaluate properties of a document for scoring purposes at very low cost.\n\n\nSince the scoring functions already have access to the DocumentMetaData, which contains document flags and score,\nWe can add custom payloads that can be evaluated in run-time.\n\n\nPayloads are NOT indexed and are not treated by the engine in any way. They are simply there for the purpose \nof evaluating them in query time, and optionally retrieving them. They can be JSON objects, strings, or preferably, \nif you are interested in fast evaluation, some sort of binary encoded data which is fast to decode.\n\n\nAdding payloads for documents:\n\n\nWhen inserting a document using FT.ADD, you can ask RediSearch to store an arbitrary binary safe string as the document payload.\nThis is done with the PAYLOAD keyword:\n\n\nFT.ADD {index_name} {doc_id} {score} PAYLOAD {payload} FIELDS {field} {data}...\n\n\n\n\n\nEvaluating Payloads in Query Time\n\n\nWhen imlplementing a scoring function, the signature of the function exposed is:\n\n\ndouble\n \n(\n*\nScoringFunction\n)(\nDocumentMetadata\n \n*\ndmd\n,\n \nIndexResult\n \n*\nh\n);\n\n\n\n\n\n\n\n\nNOTE: currently scoring functions cannot be dynamically added, and forking the engine and replacing them is required.\n\n\n\n\nDocumentMetaData includes a few fields, one of them being the payload. It wraps a simple byte array with\narbitrary length:\n\n\ntypedef\n \nstruct\n  \n{\n\n    \nchar\n \n*\ndata\n,\n\n    \nuint32_t\n \nlen\n;\n\n\n}\n \nDocumentPayload\n;\n\n\n\n\n\n\nIf no payload was set to the document, it is simply NULL. If it is not, you can go ahead and decode it.\nIt is recommended to encode some metadata about the payload inside it, like a leading version number, etc.\n\n\nRetrieving payloads from documents\n\n\nWhen searching, it is possible to request the document payloads from the engine. \n\n\nThis is done by adding the keyword \nWITHPAYLOADS\n to \nFT.SEARCH\n. \n\n\nIf \nWITHPAYLOADS\n is set, the payloads follow the document id in the returned result. \nIf \nWITHSCORES\n is set as well, the payloads follow the scores. e.g.:\n\n\n127.0.0.1:6379\n FT.CREATE foo SCHEMA bar TEXT\nOK\n127.0.0.1:6379\n FT.ADD foo doc2 1.0 PAYLOAD \nhi there!\n FIELDS bar \nhello\n\nOK\n127.0.0.1:6379\n FT.SEARCH foo \nhello\n WITHPAYLOADS WITHSCORES\n1) (integer) 1\n2) \ndoc2\n           # id\n3) \n1\n              # score\n4) \nhi there!\n      # payload\n5) 1) \nbar\n         # fields\n   2) \nhello", 
            "title": "Document Payloads"
        }, 
        {
            "location": "/payloads/#document-payloads", 
            "text": "Usually, redisearch stores documents as HASH keys. But if you want to access some data for \naggregation or scoring functions, we might want to store that data as an inline payload. \nThis will allow us to evaluate properties of a document for scoring purposes at very low cost.  Since the scoring functions already have access to the DocumentMetaData, which contains document flags and score,\nWe can add custom payloads that can be evaluated in run-time.  Payloads are NOT indexed and are not treated by the engine in any way. They are simply there for the purpose \nof evaluating them in query time, and optionally retrieving them. They can be JSON objects, strings, or preferably, \nif you are interested in fast evaluation, some sort of binary encoded data which is fast to decode.", 
            "title": "Document Payloads"
        }, 
        {
            "location": "/payloads/#adding-payloads-for-documents", 
            "text": "When inserting a document using FT.ADD, you can ask RediSearch to store an arbitrary binary safe string as the document payload.\nThis is done with the PAYLOAD keyword:  FT.ADD {index_name} {doc_id} {score} PAYLOAD {payload} FIELDS {field} {data}...", 
            "title": "Adding payloads for documents:"
        }, 
        {
            "location": "/payloads/#evaluating-payloads-in-query-time", 
            "text": "When imlplementing a scoring function, the signature of the function exposed is:  double   ( * ScoringFunction )( DocumentMetadata   * dmd ,   IndexResult   * h );    NOTE: currently scoring functions cannot be dynamically added, and forking the engine and replacing them is required.   DocumentMetaData includes a few fields, one of them being the payload. It wraps a simple byte array with\narbitrary length:  typedef   struct    { \n     char   * data , \n     uint32_t   len ;  }   DocumentPayload ;   If no payload was set to the document, it is simply NULL. If it is not, you can go ahead and decode it.\nIt is recommended to encode some metadata about the payload inside it, like a leading version number, etc.", 
            "title": "Evaluating Payloads in Query Time"
        }, 
        {
            "location": "/payloads/#retrieving-payloads-from-documents", 
            "text": "When searching, it is possible to request the document payloads from the engine.   This is done by adding the keyword  WITHPAYLOADS  to  FT.SEARCH .   If  WITHPAYLOADS  is set, the payloads follow the document id in the returned result. \nIf  WITHSCORES  is set as well, the payloads follow the scores. e.g.:  127.0.0.1:6379  FT.CREATE foo SCHEMA bar TEXT\nOK\n127.0.0.1:6379  FT.ADD foo doc2 1.0 PAYLOAD  hi there!  FIELDS bar  hello \nOK\n127.0.0.1:6379  FT.SEARCH foo  hello  WITHPAYLOADS WITHSCORES\n1) (integer) 1\n2)  doc2            # id\n3)  1               # score\n4)  hi there!       # payload\n5) 1)  bar          # fields\n   2)  hello", 
            "title": "Retrieving payloads from documents"
        }
    ]
}